{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "task_1_main_BERT2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3PxOsuS7Bi0g"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "afc061b20d8045ab8b99aafbbe08a6b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_47b05591612e44f39864d782db111c68",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ac755eb1f6c4216bd5b9505d060b803",
              "IPY_MODEL_bc672e0da807478ebf9a4dffa18f3e81"
            ]
          }
        },
        "47b05591612e44f39864d782db111c68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ac755eb1f6c4216bd5b9505d060b803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf41ba10c741479eac2f46e3c5bdb410",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab427131ba9540eb87dcc518c89d043c"
          }
        },
        "bc672e0da807478ebf9a4dffa18f3e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b1bf041bf034bdc9722cd799717c1c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.34kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_733b4a63fb2a4dddb826a4c0b3fe7b31"
          }
        },
        "bf41ba10c741479eac2f46e3c5bdb410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab427131ba9540eb87dcc518c89d043c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b1bf041bf034bdc9722cd799717c1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "733b4a63fb2a4dddb826a4c0b3fe7b31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67fd0ce88a6b41b8ade960627c6fcd5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8333b28d5e6b4aae8b5ac952ddf10f06",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a472a062cd0c4841ae1ccd1171c73c59",
              "IPY_MODEL_40ee08e59d4f45f4bd5e3137ba00fcfc"
            ]
          }
        },
        "8333b28d5e6b4aae8b5ac952ddf10f06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a472a062cd0c4841ae1ccd1171c73c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb06801cf3cb406796ce4999f2402b62",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b40d3ed622094c95a3d69a49b2b6734b"
          }
        },
        "40ee08e59d4f45f4bd5e3137ba00fcfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_542462b3d38f418395f348893bb78233",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [01:44&lt;00:00, 4.22MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e2934dc566e4f60af2b1e88fb0557be"
          }
        },
        "fb06801cf3cb406796ce4999f2402b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b40d3ed622094c95a3d69a49b2b6734b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "542462b3d38f418395f348893bb78233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e2934dc566e4f60af2b1e88fb0557be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNppdFiGaRLE"
      },
      "source": [
        "### Coursework coding instructions (please also see full coursework spec)\n",
        "\n",
        "Please choose if you want to do either Task 1 or Task 2. You should write your report about one task only.\n",
        "\n",
        "For the task you choose you will need to do two approaches:\n",
        "  - Approach 1, which can use use pre-trained embeddings / models\n",
        "  - Approach 2, which should not use any pre-trained embeddings or models\n",
        "We should be able to run both approaches from the same colab file\n",
        "\n",
        "#### Running your code:\n",
        "  - Your models should run automatically when running your colab file without further intervention\n",
        "  - For each task you should automatically output the performance of both models\n",
        "  - Your code should automatically download any libraries required\n",
        "\n",
        "#### Structure of your code:\n",
        "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
        "  - Otherwise there are no restrictions on what you can do in your code\n",
        "\n",
        "#### Documentation:\n",
        "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
        "\n",
        "#### Reproducibility:\n",
        "  - Your .README file should explain how to replicate the different experiments mentioned in your report\n",
        "\n",
        "Good luck! We are really looking forward to seeing your reports and your model code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8IanU_MaRLH"
      },
      "source": [
        "#Todo\n",
        "#Remove punctuation\n",
        "#Use embedding that represents headslines\n",
        "#Tokenizer with special token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WfDREnZaRLI",
        "outputId": "392fa9ce-035b-4b14-adb1-a802f41bbf40"
      },
      "source": [
        "# You will need to download any word embeddings required for your code, e.g.:\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n",
        "\n",
        "#! pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-18 14:46:02--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-02-18 14:46:02--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-02-18 14:46:02--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip          6%[>                   ]  50.81M  1.79MB/s    eta 6m 17s ^C\n",
            "Archive:  glove.6B.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of glove.6B.zip or\n",
            "        glove.6B.zip.zip, and cannot find glove.6B.zip.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYZiUqXFghTY",
        "outputId": "990fa468-09cf-4af5-b425-ce8963ecb5e8"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6XoHzG_bHDo",
        "outputId": "84bd9d0f-df8b-43df-bf96-38bd9bdd79b9"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\r\u001b[K     |▏                               | 10kB 22.4MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 30.6MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 23.0MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 20.6MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 17.8MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 15.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71kB 15.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81kB 15.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 92kB 14.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102kB 14.6MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 14.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 122kB 14.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 133kB 14.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 143kB 14.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 153kB 14.6MB/s eta 0:00:01\r\u001b[K     |███                             | 163kB 14.6MB/s eta 0:00:01\r\u001b[K     |███                             | 174kB 14.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 184kB 14.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 194kB 14.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 204kB 14.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 215kB 14.6MB/s eta 0:00:01\r\u001b[K     |████                            | 225kB 14.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 235kB 14.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 245kB 14.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 256kB 14.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 266kB 14.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 276kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 286kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 296kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 307kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 317kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 327kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 337kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 348kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 358kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 368kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 378kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 389kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 399kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 409kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 419kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 430kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 440kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 450kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 460kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 471kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 481kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 491kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 501kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 512kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 522kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 532kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 542kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 552kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 563kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 573kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 583kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 593kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 604kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 614kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 624kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 634kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 645kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 655kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 665kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 675kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 686kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 696kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 706kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 716kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 727kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 737kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 747kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 757kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 768kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 778kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 788kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 798kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 808kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 819kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 829kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 839kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 849kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 860kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 870kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 880kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 890kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 901kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 911kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 921kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 931kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 942kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 952kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 962kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 972kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 983kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 993kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.0MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.0MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.0MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.0MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.0MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.3MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.3MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.3MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.3MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.4MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.4MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.4MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.4MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.5MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.5MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.5MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.5MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.5MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.6MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.6MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.6MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.6MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.6MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.7MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.7MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.7MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.7MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.7MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.7MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.7MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.7MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.8MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.8MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.8MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.8MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.8MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 14.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 53.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=34648dde7dc265353ebb63ae0d83de2736dfa4e55c78270ca6b9813b0b029262\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFcC8gvDaRLI"
      },
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import codecs\n",
        "from transformers import RobertaTokenizer, RobertaModel, BertTokenizer, BertModel, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import re\n",
        "import pdb\n",
        "import random\n",
        "import csv\n",
        "import tqdm\n",
        "import multiprocessing\n",
        "import pickle\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84OyAVNSaRLJ",
        "outputId": "9c763b2e-74cb-4bfa-f70c-9fb57dbe431f"
      },
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "2gxbblziaRLK",
        "outputId": "c8fb8a60-2eb0-4639-fe66-1ef8a045c819"
      },
      "source": [
        "# Load data\n",
        "train_df = pd.read_csv('drive/MyDrive/NLP_Coursework/ic_nlp_cw/task-1/train.csv')\n",
        "train_df\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14530</td>\n",
              "      <td>France is ‘ hunting down its citizens who join...</td>\n",
              "      <td>twins</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13034</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian tr...</td>\n",
              "      <td>bowling</td>\n",
              "      <td>33110</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8731</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor ...</td>\n",
              "      <td>party</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76</td>\n",
              "      <td>In an apparent first , Iran and Israel &lt;engage...</td>\n",
              "      <td>slap</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6164</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled &lt;Vi...</td>\n",
              "      <td>school</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9647</th>\n",
              "      <td>10899</td>\n",
              "      <td>State officials blast ' unprecedented ' DHS &lt;m...</td>\n",
              "      <td>idea</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9648</th>\n",
              "      <td>1781</td>\n",
              "      <td>Protesters Rally for &lt;Refugees/&gt; Detained at J...</td>\n",
              "      <td>stewardesses</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9649</th>\n",
              "      <td>5628</td>\n",
              "      <td>Cruise line Carnival Corp. joins the fight aga...</td>\n",
              "      <td>raisin</td>\n",
              "      <td>21000</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9650</th>\n",
              "      <td>14483</td>\n",
              "      <td>Columbia police hunt woman seen with &lt;gun/&gt; ne...</td>\n",
              "      <td>cake</td>\n",
              "      <td>32200</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9651</th>\n",
              "      <td>5255</td>\n",
              "      <td>Here 's What 's In The House-Approved Health &lt;...</td>\n",
              "      <td>food</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9652 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... meanGrade\n",
              "0     14530  ...       0.2\n",
              "1     13034  ...       1.6\n",
              "2      8731  ...       1.0\n",
              "3        76  ...       0.4\n",
              "4      6164  ...       0.0\n",
              "...     ...  ...       ...\n",
              "9647  10899  ...       0.0\n",
              "9648   1781  ...       0.4\n",
              "9649   5628  ...       0.6\n",
              "9650  14483  ...       1.4\n",
              "9651   5255  ...       0.4\n",
              "\n",
              "[9652 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tkg9n8OUIs7",
        "outputId": "09ce1a2b-994b-4a77-f191-86f4d654ab30"
      },
      "source": [
        "extra_data = pd.read_csv('drive/MyDrive/NLP_Coursework/ic_nlp_cw/extra_train_data.csv')\n",
        "#train_df = train_df + extra_data\n",
        "test_df = pd.read_csv('drive/MyDrive/NLP_Coursework/ic_nlp_cw/task-1/dev.csv')\n",
        "#train_df\n",
        "new_train_df = pd.concat((train_df, extra_data))\n",
        "#new_train_df.loc[new_train_df['id'] == 9647]\n",
        "len(new_train_df)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17900"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "wHzTeNIJnoXj",
        "outputId": "2086f35a-9d7f-4129-8a45-c8384d7155d5"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1723</td>\n",
              "      <td>Thousands of gay and bisexual &lt;men/&gt; convicted of long-abolished sexual offences are posthumously pardoned</td>\n",
              "      <td>swans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12736</td>\n",
              "      <td>Special &lt;prosecutor/&gt; appointed to Trump Russia</td>\n",
              "      <td>chef</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12274</td>\n",
              "      <td>Spanish police detain man and search Ripoll addresses in hunt for terror &lt;suspects/&gt;</td>\n",
              "      <td>squad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8823</td>\n",
              "      <td>N.Y. Times &lt;reprimands/&gt; reporter for sharing ' unfounded rumor ' about Melania Trump</td>\n",
              "      <td>applauds</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5087</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Russian &lt;Missile/&gt; striking Florida conveniently right on top of USSOCOM headquarters at MacDill AFB .</td>\n",
              "      <td>balloon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2414</th>\n",
              "      <td>1202</td>\n",
              "      <td>Supreme &lt;Court/&gt; Once Again Strikes Down Racial Gerrymandering In North Carolina</td>\n",
              "      <td>leaders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2415</th>\n",
              "      <td>14764</td>\n",
              "      <td>Trump Mocks Schumer ’s Tears ; Vows to ‘ Make America &lt;Safe/&gt; Again ’</td>\n",
              "      <td>Insane</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2416</th>\n",
              "      <td>12595</td>\n",
              "      <td>US government memo on the &lt;danger/&gt; of leaking to media has been leaked</td>\n",
              "      <td>amusement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2417</th>\n",
              "      <td>70</td>\n",
              "      <td>Newt Gingrich : Join Me in Supporting Judge Roy Moore to &lt;Advance/&gt; the President ’s Agenda</td>\n",
              "      <td>Molest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2418</th>\n",
              "      <td>14315</td>\n",
              "      <td>In Search of Donald Trump at His Boyhood &lt;Home/&gt;</td>\n",
              "      <td>Castle</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2419 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ...       edit\n",
              "0     1723   ...  swans    \n",
              "1     12736  ...  chef     \n",
              "2     12274  ...  squad    \n",
              "3     8823   ...  applauds \n",
              "4     5087   ...  balloon  \n",
              "...    ...   ...      ...  \n",
              "2414  1202   ...  leaders  \n",
              "2415  14764  ...  Insane   \n",
              "2416  12595  ...  amusement\n",
              "2417  70     ...  Molest   \n",
              "2418  14315  ...  Castle   \n",
              "\n",
              "[2419 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vI4-ouDURXu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQbm--SyaRLL"
      },
      "source": [
        "# Number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# Proportion of training data for train compared to dev\n",
        "train_proportion = 0.8"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PxOsuS7Bi0g"
      },
      "source": [
        "### Training for BILSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxhwWCz6aRLL"
      },
      "source": [
        "# We define our training loop\n",
        "def train(train_iter, dev_iter, model, number_epoch, bert=False):\n",
        "    \"\"\"\n",
        "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "    \"\"\"\n",
        "\n",
        "    train_losses = np.zeros(number_epoch)\n",
        "    valid_losses = np.zeros(number_epoch)\n",
        "    print(\"Training model.\")\n",
        "\n",
        "    for epoch in range(1, number_epoch+1):\n",
        "\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_sse = 0\n",
        "        no_observations = 0  # Observations used for training so far\n",
        "\n",
        "        for batch in train_iter:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            feature, target = batch\n",
        "            feature_1= feature[0].to(device)\n",
        "            feature_2 = feature[1].to(device)\n",
        "            target = target.to(device)\n",
        "            # for RNN:\n",
        "            model.batch_size = target.shape[0]\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            model.hidden_1 = model.init_hidden()\n",
        "            model.hidden_2 = model.init_hidden()\n",
        "\n",
        "            feature = (feature_1, feature_2)\n",
        "            predictions = model(feature).squeeze(1)\n",
        "\n",
        "            #print(predictions.shape)\n",
        "            #print(target.shape)\n",
        "\n",
        "            loss = loss_fn(predictions, target)\n",
        "                        \n",
        "            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy()) \n",
        "            \n",
        "            loss.backward(retain_graph=True)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_sse += sse\n",
        "\n",
        "        valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
        "\n",
        "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
        "        train_losses[epoch-1] = epoch_loss\n",
        "        valid_losses[epoch-1] = valid_loss\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
        "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')\n",
        "    return train_losses, valid_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAPacdgOaRLM"
      },
      "source": [
        "# We evaluate performance on our dev set\n",
        "def eval(data_iter, model):\n",
        "    \"\"\"\n",
        "    Evaluating model performance on the dev set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_sse = 0\n",
        "    pred_all = []\n",
        "    trg_all = []\n",
        "    no_observations = 0\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_iter:\n",
        "            feature, target = batch\n",
        "            feature_1= feature[0].to(device)\n",
        "            feature_2 = feature[1].to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            feature = (feature_1, feature_2)\n",
        "\n",
        "            # for RNN:\n",
        "            model.batch_size = target.shape[0]\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            model.hidden_1 = model.init_hidden()\n",
        "            model.hidden_2 = model.init_hidden()\n",
        "\n",
        "            predictions = model(feature).squeeze(1)\n",
        "            #predictions.requires_grad = True\n",
        "            loss = loss_fn(predictions, target)\n",
        "\n",
        "            # We get the mse\n",
        "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
        "            sse, __ = model_performance(pred, trg)\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_sse += sse\n",
        "            pred_all.extend(pred)\n",
        "            trg_all.extend(trg)\n",
        "\n",
        "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcchQKtEaRLN"
      },
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "    \"\"\"\n",
        "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
        "    \"\"\"\n",
        "\n",
        "    sq_error = (output - target)**2\n",
        "\n",
        "    sse = np.sum(sq_error)\n",
        "    mse = np.mean(sq_error)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    if print_output:\n",
        "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
        "\n",
        "    return sse, mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "uO4Kv0URaRLN",
        "outputId": "c0470287-1bbe-4a9d-99c1-21cec8abdff8"
      },
      "source": [
        "'''\n",
        "def create_vocab(data):\n",
        "    \"\"\"\n",
        "    Creating a corpus of all the tokens used\n",
        "    \"\"\"\n",
        "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
        "\n",
        "    for sentence in data:\n",
        "\n",
        "        tokenized_sentence = []\n",
        "\n",
        "        for token in sentence.split(' '): # simplest split is\n",
        "\n",
        "            tokenized_sentence.append(token)\n",
        "\n",
        "        tokenized_corpus.append(tokenized_sentence)\n",
        "\n",
        "    # Create single list of all vocabulary\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "    for sentence in tokenized_corpus:\n",
        "\n",
        "        for token in sentence:\n",
        "\n",
        "            if token not in vocabulary:\n",
        "\n",
        "                if True:\n",
        "                    vocabulary.append(token)\n",
        "\n",
        "    return vocabulary, tokenized_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-d3ae31c862b2>\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    return vocabulary, tokenized_corpus\u001b[0m\n\u001b[0m                                       \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSQ-36SdaRLO"
      },
      "source": [
        "# To create our vocab\n",
        "\n",
        "def custom_tokenizer(nlp):\n",
        "    \n",
        "    replacement_re = re.compile(r'^<*/>') #do not split replacement format\n",
        "    prefix_re = re.compile(r'''^[\\[\\(\"]''')\n",
        "    suffix_re = re.compile(r''',[\\]\\)\"']$''')\n",
        "    infix_re = re.compile(r'''[-\\,.~]''')\n",
        "    \n",
        "    \n",
        "    return Tokenizer(nlp.vocab,\n",
        "                     token_match = replacement_re.match,\n",
        "                     prefix_search=prefix_re.search,\n",
        "                     suffix_search=suffix_re.search,\n",
        "                     infix_finditer = infix_re.finditer  \n",
        "                    )\n",
        "\n",
        "\n",
        "\n",
        "def preprocessor(data,edits):\n",
        "    \"\"\"\n",
        "    Creating a corpus of all the tokens used\n",
        "    \"\"\"\n",
        "    punctuation = \"\\\":\\.,\"\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    nlp.tokenizer = custom_tokenizer(nlp)\n",
        "    \n",
        "    tokenized_corpus_1= [] # Let us put the tokenized corpus in a list\n",
        "    tokenized_corpus_2= []\n",
        "    \n",
        "    \n",
        "    for i, sentence in enumerate(data):\n",
        "\n",
        "        sentence = sentence.lower()\n",
        "        tokenized_sentence_1 = []\n",
        "        tokenized_sentence_2 = []\n",
        "\n",
        "        for token in nlp(sentence): # simplest split is\n",
        "\n",
        "            if token.text in punctuation:\n",
        "                continue\n",
        "            else:\n",
        "                \n",
        "                if token.text[0] == '<':\n",
        "                    tokenized_sentence_1.append(\"???\")\n",
        "                    tokenized_sentence_2.append(\"???\")\n",
        "                    \n",
        "                    tokenized_sentence_2.append(edits[i])\n",
        "\n",
        "                    \n",
        "                    tokenized_sentence_1.append(token.text[1:-2])\n",
        "                else:\n",
        "                    tokenized_sentence_2.append(token.text)\n",
        "                \n",
        "                    tokenized_sentence_1.append(token.text)\n",
        "\n",
        "\n",
        "        tokenized_corpus_1.append(tokenized_sentence_1)\n",
        "        tokenized_corpus_2.append(tokenized_sentence_2)\n",
        "        #print(tokenized_corpus_1[:5])\n",
        "        #print(tokenized_corpus_2[:5])\n",
        "\n",
        "    # Create single list of all vocabulary\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "    for sentence in tokenized_corpus_1:\n",
        "\n",
        "        for token in sentence:\n",
        "\n",
        "            if token not in vocabulary:\n",
        "\n",
        "                if True:\n",
        "                    vocabulary.append(token)\n",
        "    \n",
        "    for token in edits:\n",
        "        \n",
        "        if token not in vocabulary:\n",
        "            \n",
        "            vocabulary.append(token)\n",
        "\n",
        "    return vocabulary, tokenized_corpus_1, tokenized_corpus_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_faSla0aknz"
      },
      "source": [
        "'''\n",
        "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def preprocessor_bert(data,edits):\n",
        "    \"\"\"\n",
        "    Creating a corpus of all the tokens used\n",
        "    \"\"\"\n",
        "    next = False\n",
        "    punctuation = \"\\\":\\.,\"\n",
        "    #nlp = spacy.load(\"en_core_web_sm\")\n",
        "    \n",
        "    #nlp.tokenizer = custom_tokenizer(nlp)\n",
        "    \n",
        "    tokenized_corpus_1= [] # Let us put the tokenized corpus in a list\n",
        "    tokenized_corpus_2= []\n",
        "    tokenized_mask_corpus = []\n",
        "    \n",
        "    \n",
        "    for i, sentence in enumerate(data):\n",
        "\n",
        "        sentence = sentence.lower()\n",
        "        tokenized_sentence_1 = []\n",
        "        tokenized_sentence_2 = []\n",
        "        tokenized_mask_sentence = []\n",
        "\n",
        "        for token in tokenizer_bert.tokenize(sentence): # simplest split is\n",
        "\n",
        "            if token in punctuation:\n",
        "                continue\n",
        "            else:\n",
        "                \n",
        "                if token == '<':\n",
        "                    print(token)\n",
        "                    next = True\n",
        "\n",
        "                    \n",
        "                    #tokenized_sentence_2.append(edits[i])\n",
        "\n",
        "                    \n",
        "                    #tokenized_sentence_1.append(token[1:-2])\n",
        "                elif token == '>' or token == '/':\n",
        "                    continue\n",
        "                else:\n",
        "                    tokenized_sentence_1.append(token)\n",
        "                    \n",
        "                    if next:\n",
        "                        tokenized_sentence_2.append(edits[i])\n",
        "                        tokenized_mask_sentence.append(1)\n",
        "                        next = False\n",
        "                    else:\n",
        "                        tokenized_sentence_2.append(token)\n",
        "                        tokenized_mask_sentence.append(0)\n",
        "                \n",
        "        tokenized_corpus_1.append(tokenized_sentence_1)\n",
        "        tokenized_corpus_2.append(tokenized_sentence_2)\n",
        "        tokenized_mask_corpus.append(tokenized_mask_sentence)\n",
        "        print(tokenized_corpus_1[:5])\n",
        "        print(tokenized_corpus_2[:5])\n",
        "        print(tokenized_mask_corpus[:5])\n",
        "        if i==3:\n",
        "          raise\n",
        "    # Create single list of all vocabulary\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "    for sentence in tokenized_corpus_1:\n",
        "\n",
        "        for token in sentence:\n",
        "\n",
        "            if token not in vocabulary:\n",
        "\n",
        "                if True:\n",
        "                    vocabulary.append(token)\n",
        "    \n",
        "    for token in edits:\n",
        "        \n",
        "        if token not in vocabulary:\n",
        "            \n",
        "            vocabulary.append(token)\n",
        "\n",
        "    return vocabulary, tokenized_corpus_1, tokenized_corpus_2\n",
        "preprocessor_bert(training_data,train_df['edit'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOOe3Ca7aRLP"
      },
      "source": [
        "'''def collate_fn_padd(batch):\n",
        "    #We add padding to our minibatches and create tensors for our model\n",
        "\n",
        "\n",
        "    batch_labels = [l for f, l in batch]\n",
        "    batch_features = [f for f, l in batch]\n",
        "\n",
        "    batch_features_len = [len(f) for f, l in batch]\n",
        "\n",
        "    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
        "\n",
        "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
        "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
        "\n",
        "    batch_labels = torch.FloatTensor(batch_labels)\n",
        "\n",
        "    return seq_tensor, batch_labels\n",
        "'''\n",
        "def collate_fn_padd(batch):\n",
        "    \n",
        "    #We add padding to our minibatches and create tensors for our model\n",
        "    \n",
        "\n",
        "    batch_labels = [l for f, g, l in batch]\n",
        "    batch_features = [(f,g) for f, g, l in batch]\n",
        "    \n",
        "\n",
        "    batch_features_len = [len(f) for f, g, l in batch]\n",
        "\n",
        "\n",
        "    seq_tensor_1 = torch.zeros((len(batch), 50)).long()\n",
        "    seq_tensor_2 = torch.zeros((len(batch), 50)).long()\n",
        "\n",
        "    \n",
        "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
        "        seq_tensor_1[idx, :seqlen] = torch.LongTensor(seq[0])\n",
        "        seq_tensor_2[idx, :seqlen] = torch.LongTensor(seq[1])\n",
        "    batch_labels = torch.FloatTensor(batch_labels)\n",
        "    \n",
        "\n",
        "    return (seq_tensor_1, seq_tensor_2), batch_labels\n",
        "\n",
        "'''\n",
        "def collate_fn_pad(batch):\n",
        "\n",
        "    original, edit, labels = zip(*batch)\n",
        "    padded_original = torch.nn.utils.rnn.pad_sequence(original, batch_first=True,padding_value=0)\n",
        "    padded_edit = torch.nn.utils.rnn.pad_sequence(edit, batch_first=True,padding_value=0)\n",
        "    labels = torch.Tensor(labels)\n",
        "    return (padded_org, padded_edit, labels)\n",
        "'''\n",
        "\n",
        "\n",
        "class Task1Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, train_data, labels):\n",
        "        self.x_train = train_data\n",
        "        self.y_train = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_train)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.x_train[item], self.y_train[item]\n",
        "    \n",
        "class Task1Dataset_double(Dataset):\n",
        "\n",
        "    def __init__(self, train_data_1,train_data_2, labels):\n",
        "        self.x_train_1 = train_data_1\n",
        "        self.x_train_2 = train_data_2\n",
        "        self.y_train = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_train)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.x_train_1[item],self.x_train_2[item], self.y_train[item]    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F1kXohWaRLR"
      },
      "source": [
        "class BiLSTM_double(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
        "        super(BiLSTM_double, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm_1 = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "        self.lstm_2 = nn.LSTM(embedding_dim,hidden_dim, bidirectional = True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.fc = nn.Linear(2*50*100, hidden_dim*2)\n",
        "        self.fc2 = nn.Linear(hidden_dim*2, hidden_dim//2)\n",
        "        self.fc3 = nn.Linear(hidden_dim//2, hidden_dim//4)\n",
        "\n",
        "        self.hidden_1 = self.init_hidden()\n",
        "        self.hidden_2 = self.init_hidden()\n",
        "        self.hidden2label = nn.Linear(hidden_dim//4, 1)\n",
        "\n",
        "\n",
        "        self.d1 = nn.Dropout(0.3)\n",
        "        self.d2 = nn.Dropout(0.3)\n",
        "        self.d3 = nn.Dropout(0.3)\n",
        "        self.d4 = nn.Dropout(0.3)\n",
        "        self.d5 = nn.Dropout(0.3)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "        \n",
        "        return torch.zeros(2, self.batch_size, self.hidden_dim, requires_grad = True).to(self.device), \\\n",
        "               torch.zeros(2, self.batch_size, self.hidden_dim, requires_grad = True).to(self.device)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        self.embedded_1 = self.embedding(sentence[0])\n",
        "        self.embedded_1 = self.embedded_1.permute(1, 0, 2) #Needed for LSTMs\n",
        "\n",
        "        self.embedded_2 = self.embedding(sentence[1])\n",
        "        self.embedded_2 = self.embedded_2.permute(1, 0, 2) #Needed for LSTMs\n",
        "\n",
        "        #lstm_out : (seq_len,batch_size,num_directions (2) * hidden_size (50))\n",
        "        #hidden : (num_layers * num_directions, batch_size,hidden_size)\n",
        "        lstm_out_1, self.hidden_1 = self.lstm_1(\n",
        "            self.embedded_1.view(len(self.embedded_1), self.batch_size, self.embedding_dim), self.hidden_1)\n",
        "        \n",
        "        lstm_out_1 = F.leaky_relu(self.d1(lstm_out_1))\n",
        "\n",
        "        lstm_out_2, self.hidden_2 = self.lstm_2(\n",
        "            self.embedded_2.view(len(self.embedded_2), self.batch_size, self.embedding_dim), self.hidden_2)\n",
        "        \n",
        "        lstm_out_2 = F.leaky_relu(self.d2(lstm_out_2))\n",
        "        \n",
        "        #out : (1)\n",
        "        lstm_out_1 = lstm_out_1.permute(1,0,2)\n",
        "        lstm_out_2 = lstm_out_2.permute(1,0,2)\n",
        "\n",
        "        out1 = self.fc(torch.cat((lstm_out_1.reshape(self.batch_size, -1),lstm_out_2.reshape(self.batch_size, -1)), dim = 1))\n",
        "        out1 = F.leaky_relu(self.d3(out1))\n",
        "\n",
        "        out2 = self.fc2(out1)\n",
        "        out2 = F.leaky_relu(self.d4(out2))\n",
        "\n",
        "        out3 = self.fc3(out2)\n",
        "        out3 = F.leaky_relu(self.d5(out3))\n",
        "\n",
        "        out = self.hidden2label(out3)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JSWm-Q5nIxX"
      },
      "source": [
        "## Approach 1 code, using functions defined above:\n",
        "\n",
        "# We set our training data and test data\n",
        "training_data = train_df['original']\n",
        "test_data = test_df['original']\n",
        "\n",
        "# Creating word vectors\n",
        "#training_vocab, training_tokenized_corpus = create_vocab(training_data)\n",
        "#test_vocab, test_tokenized_corpus = create_vocab(test_data)\n",
        "training_vocab, training_tokenized_corpus_1,training_tokenized_corpus_2=  preprocessor(training_data,train_df['edit'])\n",
        "test_vocab, test_tokenized_corpus_1,test_tokenized_corpus_2=  preprocessor(test_data,test_df['edit'])\n",
        "\n",
        "#print(\"Vocabulary individual creation - done\")\n",
        "\n",
        "# Creating joint vocab from test and train:\n",
        "#joint_vocab, joint_tokenized_corpus = create_vocab(pd.concat([training_data, test_data]))\n",
        "joint_vocab, joint_tokenized_corpus_1,joint_tokenized_corpus_2 = preprocessor(pd.concat([training_data, test_data]),pd.concat([train_df['edit'],test_df['edit']],ignore_index = True))\n",
        "\n",
        "print(\"Vocabulary joined creation - done\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Vocab created.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeXy7v7dnQGq"
      },
      "source": [
        "# We create representations for our tokens\n",
        "wvecs = [] # word vectors\n",
        "word2idx = [] # word2index\n",
        "idx2word = []\n",
        "\n",
        "#Add special character -> embedding vector of ones \n",
        "wvecs.append(np.ones(100))\n",
        "\n",
        "# This is a large file, it will take a while to load in the memory!\n",
        "with codecs.open('glove.6B.100d.txt', 'r','utf-8') as f:\n",
        "  index = 1 #zero padding\n",
        "  for line in f.readlines():\n",
        "    # Ignore the first line - first line typically contains vocab, dimensionality\n",
        "    if len(line.strip().split()) > 3:\n",
        "      word = line.strip().split()[0]\n",
        "      if word in joint_vocab:\n",
        "          (word, vec) = (word,\n",
        "                     list(map(float,line.strip().split()[1:])))\n",
        "          wvecs.append(vec)\n",
        "          word2idx.append((word, index))\n",
        "          idx2word.append((index, word))\n",
        "          index += 1\n",
        "\n",
        "wvecs = np.array(wvecs)\n",
        "word2idx = dict(word2idx)\n",
        "idx2word = dict(idx2word)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ze3glIrVMmj"
      },
      "source": [
        "word2idx['<unk>'] = 1\n",
        "idx2word[1] = '<unk>'\n",
        "mean = np.mean(wvecs, axis=0) # initialize unknown token as mean\n",
        "#wvecs = np.vstack((wvecs, mean))\n",
        "wvecs[0] = mean\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgcGpchbQOO-"
      },
      "source": [
        "\n",
        "\n",
        "vectorized_seqs_1 = [[word2idx[tok] if tok in word2idx else word2idx['<unk>'] for tok in seq] for seq in training_tokenized_corpus_1]\n",
        "vectorized_seqs_2 = [[word2idx[tok] if tok in word2idx else word2idx['<unk>'] for tok in seq] for seq in training_tokenized_corpus_2]\n",
        "\n",
        "\n",
        "# To avoid any sentences being empty (if no words match to our word embeddings)\n",
        "vectorized_seqs_1 = [x if len(x) > 0 else [0] for x in vectorized_seqs_1]\n",
        "vectorized_seqs_2 = [x if len(x) > 0 else [0] for x in vectorized_seqs_2]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XzJHcQ_aRLT",
        "scrolled": true
      },
      "source": [
        "\n",
        "INPUT_DIM = len(word2idx)\n",
        "EMBEDDING_DIM = wvecs.shape[1]\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "model = BiLSTM_double(EMBEDDING_DIM, 50, INPUT_DIM, BATCH_SIZE, device)\n",
        "\n",
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(params)\n",
        "#print(\"Total number of parameters is: {​​}​​\".format(params))\n",
        "\n",
        "print(model)\n",
        "\n",
        "print(\"Model initialised.\")\n",
        "\n",
        "model.to(device)\n",
        "# We provide the model with our embeddings\n",
        "#x = np.concatenate((wvecs,wvecs),axis=1)\n",
        "model.embedding.weight.data.copy_(torch.from_numpy(wvecs))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8ovZX23ECX4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot(train_losses,valid_losses,num_epochs):\n",
        "  epochs = list(range(num_epochs))\n",
        "  plt.plot(epochs,train_losses, label='train')\n",
        "  plt.plot(epochs,valid_losses, label='valid')\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un9wo5TPyN9L"
      },
      "source": [
        "\n",
        "feature_1 = vectorized_seqs_1\n",
        "feature_2 = vectorized_seqs_2\n",
        "\n",
        "\n",
        "# 'feature' is a list of lists, each containing embedding IDs for word tokens\n",
        "#train_and_dev = Task1Dataset(feature, train_df['meanGrade'])\n",
        "train_and_dev = Task1Dataset_double(feature_1,feature_2, train_df['meanGrade'])\n",
        "\n",
        "train_examples = round(len(train_and_dev)*train_proportion)\n",
        "dev_examples = len(train_and_dev) - train_examples\n",
        "train_dataset, dev_dataset = random_split(train_and_dev,\n",
        "                                           (train_examples,\n",
        "                                            dev_examples))\n",
        "####Shuffle might need to be true. Check later\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
        "\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
        "\n",
        "print(\"Dataloaders created.\")\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "#optimizer = torch.optim.Adam(model.parameters())\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "train_losses, valid_losses = train(train_loader, dev_loader, model, epochs)\n",
        "plot(train_losses, valid_losses, len(train_losses))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJHjgo5XEELW"
      },
      "source": [
        "# BERT VERSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huUfT43sLAmc"
      },
      "source": [
        "## Bert Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YhnKBjYLIoG"
      },
      "source": [
        " def bert_preprocessing(train_df, test_df):   \n",
        "    #instead of having two inputs out of preprocessing, edit the dataset, and add in columns which we can use as inputs\n",
        "    #we can also add an 'old' field which contains the original word \n",
        "    train_df['old'] = train_df.apply(lambda x:x['original'][x['original'].find('<')+1:x['original'].find('>')-1],axis=1)\n",
        "    test_df['old'] = test_df.apply(lambda x:x['original'][x['original'].find('<')+1:x['original'].find('>')-1],axis=1)\n",
        "\n",
        "    #first we add a field to the data which contains the edited headline\n",
        "    train_df['edited'] = train_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],\"??? \" + x['edit'] ) ,axis=1)\n",
        "    test_df['edited'] = test_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],\"??? \" + x['edit'] ) ,axis=1)\n",
        "\n",
        "    train_df['original'] = train_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],\"??? \" \n",
        "                                                                        +x['old']) ,axis=1)\n",
        "    test_df['original'] = test_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1], \"??? \" +x['old']),axis=1)\n",
        "\n",
        "\n",
        "    #and then we can add another field which includes the sentence with old word + SEP + new word\n",
        "    train_df['combined'] = train_df.apply(lambda x:x['original'] + ' [SEP] ' + x['edited'] ,axis=1)\n",
        "    test_df['combined'] = test_df.apply(lambda x:x['original'] + ' [SEP] ' +x['edited'] ,axis=1)\n",
        "    \n",
        "    return train_df, test_df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFE_obgNLjhX"
      },
      "source": [
        "def tokenizer(data):\n",
        "    # Load the BERT tokenizer.\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",do_lower_case=True)\n",
        "\n",
        "    # Get the lists of sentences and their labels  - using the finalized edited headline here\n",
        "    sentences = data['combined'].values\n",
        "    labels = data['meanGrade'].values\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                      # Sentence to encode.\n",
        "                            add_special_tokens = True, # this adds a CLS at the begining of a sentence and SEP at the end\n",
        "                            max_length = 32,           # Pad & truncate all sentences.\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks for the padded tokens\n",
        "                            return_tensors = 'pt',   # Return pytorch tensors.\n",
        "                            truncation = True\n",
        "                       )\n",
        "\n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    \n",
        "    return input_ids, attention_masks, labels"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqgR-To-MIPd",
        "outputId": "392f6184-5663-46bb-cef6-391e65f0fb6b"
      },
      "source": [
        "train_df_bert, test_df_bert = bert_preprocessing(new_train_df,test_df)\n",
        "\n",
        "\n",
        "train_ids, train_masks, train_labels = tokenizer(train_df_bert)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W1H-nAcaD5F"
      },
      "source": [
        "def processed_data_to_lists(train, training = True):\n",
        "    headls_words = [(origin_headl, new_word) for (origin_headl, new_word) in zip(train.original.to_list(), train.edited.to_list())]\n",
        "    labels_list = []\n",
        "    if training == True:\n",
        "      labels_list = train.meanGrade.to_list()\n",
        "\n",
        "    # list of tuple for original headlines and new edited headlines\n",
        "    o_headls_n_headls = []\n",
        "    new_word_list = []\n",
        "    \n",
        "    for origin_headl, new_word in headls_words:\n",
        "      # pattern\n",
        "      p = re.compile(r'\\<(.*?)\\/\\>')\n",
        "      # get the normal version of the original headline\n",
        "      origin_word = ''.join(re.findall(p, origin_headl))\n",
        "      normal_origin_headl = p.sub(origin_word, origin_headl)\n",
        "      # get the new edited headline\n",
        "      new_headl = p.sub(new_word, origin_headl)\n",
        "      # pair them and put them into the list\n",
        "      o_headls_n_headls.append((normal_origin_headl,new_headl))\n",
        "\n",
        "      new_word_list.append(new_word)\n",
        "\n",
        "    o_headls = [i for i, j in o_headls_n_headls]\n",
        "    n_headls = [j for i, j in o_headls_n_headls]\n",
        "\n",
        "    return o_headls, n_headls, new_word_list, labels_list"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY-FAWMSn6Hy"
      },
      "source": [
        "train_original, train_edited, edited_words, train_labels = processed_data_to_lists(new_train_df)\n",
        "\n",
        "test_o_headls, test_n_headls, test_new_word_list, test_labels_list = processed_data_to_lists(test_df, training=False)\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW_0b2eeo-xq"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "# the version that concatenates original sentences and new sentences\n",
        "train_encoded_inputs = tokenizer(train_original, train_edited, padding='max_length', max_length=90, truncation=True, return_tensors=\"pt\")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "QIScC-WOrqww",
        "outputId": "b636afe0-da61-4acb-9280-393cd98816e3"
      },
      "source": [
        "train_input_ids = train_encoded_inputs['input_ids']\n",
        "train_attention_mask = train_encoded_inputs['attention_mask']\n",
        "train_token_type_ids = train_encoded_inputs['token_type_ids']\n",
        "train_labels = torch.tensor(train_labels_list)\n",
        "\n",
        "train_token_type_ids[0]\n",
        "tokenizer.decode(train_input_ids.tolist()[1])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] pentagon claims 2, 000 % increase in russian trolls after syria strikes. what does that mean? [SEP] pentagon claims 2, 000 % increase in russian trolls after bowling strikes. what does that mean? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl-WQN4isKwC",
        "outputId": "6c4e97ee-e546-4862-bbc5-3adf95fb4ae9"
      },
      "source": [
        "import torch.utils.data as tud\n",
        "def fix_seed(seed=1234):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "class BERT_Dataset(tud.Dataset):\n",
        "    def __init__(self, x1, x2, x3, y1):\n",
        "        self.len = x1.shape[0]\n",
        "\n",
        "        self.x1_data = x1.to(device)\n",
        "        self.x2_data = x2.to(device)\n",
        "        self.x3_data = x3.to(device)\n",
        "        self.y1_data = y1.to(device)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x1_data[index], self.x2_data[index], self.x3_data[index], self.y1_data[index]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "fix_seed()\n",
        "# Batching for BERT\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_dataset = BERT_Dataset(train_input_ids, train_attention_mask, train_token_type_ids, train_labels)\n",
        "#test_dataset = BERT_Dataset(test_input_ids, test_attention_mask, test_token_type_ids, test_labels)\n",
        "\n",
        "train_dataloader = tud.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "#test_dataloader = tud.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "##### demo #####\n",
        "print(train_dataloader)\n",
        "\n",
        "for x1, x2, x3, y1 in train_dataloader:\n",
        "    demo_x1 = x1\n",
        "    demo_x2 = x2\n",
        "    demo_x3 = x3\n",
        "    demo_y1 = y1\n",
        "    break\n",
        "    \n",
        "print(x1.shape)\n",
        "print(x2.shape)\n",
        "print(x3.shape)\n",
        "print(y1.shape)\n",
        "print(len(train_dataloader))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7fbe19065be0>\n",
            "torch.Size([16, 90])\n",
            "torch.Size([16, 90])\n",
            "torch.Size([16, 90])\n",
            "torch.Size([16])\n",
            "1119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "afc061b20d8045ab8b99aafbbe08a6b4",
            "47b05591612e44f39864d782db111c68",
            "4ac755eb1f6c4216bd5b9505d060b803",
            "bc672e0da807478ebf9a4dffa18f3e81",
            "bf41ba10c741479eac2f46e3c5bdb410",
            "ab427131ba9540eb87dcc518c89d043c",
            "7b1bf041bf034bdc9722cd799717c1c1",
            "733b4a63fb2a4dddb826a4c0b3fe7b31",
            "67fd0ce88a6b41b8ade960627c6fcd5d",
            "8333b28d5e6b4aae8b5ac952ddf10f06",
            "a472a062cd0c4841ae1ccd1171c73c59",
            "40ee08e59d4f45f4bd5e3137ba00fcfc",
            "fb06801cf3cb406796ce4999f2402b62",
            "b40d3ed622094c95a3d69a49b2b6734b",
            "542462b3d38f418395f348893bb78233",
            "3e2934dc566e4f60af2b1e88fb0557be"
          ]
        },
        "id": "vTf3BhB3s4zf",
        "outputId": "dc4629cf-2b45-4029-f36b-ec885365c446"
      },
      "source": [
        "# Load the BertForSequenceClassification model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                        num_labels = 1,   \n",
        "                                                        output_attentions = False,\n",
        "                                                        output_hidden_states = False)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afc061b20d8045ab8b99aafbbe08a6b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67fd0ce88a6b41b8ade960627c6fcd5d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9brja9zLFR4"
      },
      "source": [
        "## Bert Training/Eval\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbPoBnC7sITC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4QrarCXbiFt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeKy-eWjF9BB"
      },
      "source": [
        "#Hyperparameters\n",
        "train_proportion = 0.8\n",
        "batch_size = 64\n",
        "lr = 8e-3\n",
        "eps = 1e-8\n",
        "epochs = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSlXJEGPQlhn"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "train_and_dev = TensorDataset(train_ids, train_masks, train_labels)\n",
        "\n",
        "train_examples = round(len(train_and_dev)*train_proportion)\n",
        "dev_examples = len(train_and_dev) - train_examples\n",
        "train_dataset, dev_dataset = random_split(train_and_dev,\n",
        "                                           (train_examples,\n",
        "                                            dev_examples))\n",
        "\n",
        "\n",
        "train_iter = DataLoader(\n",
        "            train_dataset, \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "eval_iter = DataLoader(\n",
        "            dev_dataset, \n",
        "            sampler = SequentialSampler(dev_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvvC0JgPFRyU",
        "outputId": "9bb7f053-8330-4f8f-a26a-b60e038e376b"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', # the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 1,  \n",
        "    output_attentions = False, # don't return attention weights or hidden states\n",
        "    output_hidden_states = False, \n",
        ")\n",
        "model.cuda()\n",
        "#store double values\n",
        "model = model.double()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgmAb56fbq7-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "ae087cbe-33a0-4b8c-f8d6-d30111498eeb"
      },
      "source": [
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4.\n",
        "N_EPOCHS = 1\n",
        "\n",
        "LRATE = 8e-3\n",
        "FRATE = 3e-5\n",
        "EPS = 1e-8\n",
        "WU = 0.2\n",
        "WDECAY = 0.005\n",
        "\n",
        "# best so far: N_EPOCHS = 2, LRATE = 8e-3, FRATE = 3e-5 EPS = 1e-8, WU = 0.3, WDECAY = 0.01\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "TOTSTEPS = len(train_iter) * N_EPOCHS * 2\n",
        "WUSTEPS = int(TOTSTEPS * WU)\n",
        "\n",
        "# Apply weight decay to all parameters other than bias and layer normalization terms\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "\"\"\"optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': WDECAY},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\"\"\"\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if \"bert\" not in n], 'lr': LRATE, 'weight_decay': WDECAY},\n",
        "    {'params': [p for n, p in model.named_parameters() if \"bert\" in n], 'weight_decay': WDECAY}\n",
        "]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-eb516db992f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Total number of training steps is [number of batches] x [number of epochs].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mTOTSTEPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN_EPOCHS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mWUSTEPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTOTSTEPS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mWU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_iter' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6kGoEa-RQn7"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = FRATE, eps = EPS)\n",
        "\n",
        "total_steps = len(train_iter) * epochs\n",
        "# The scheduler can actually learn the best learning rate throughout tranining\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = WUSTEPS,\n",
        "                                            num_training_steps = TOTSTEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TrotOmSEG-n"
      },
      "source": [
        "# We define our training loop\n",
        "def train2(train_iter, dev_iter, model, number_epoch):\n",
        "    \"\"\"\n",
        "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "    \"\"\"\n",
        "\n",
        "    train_losses = np.zeros(number_epoch)\n",
        "    valid_losses = np.zeros(number_epoch)\n",
        "    print(\"Training model.\")\n",
        "\n",
        "\n",
        "    for epoch in range(1, number_epoch+1):\n",
        "\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_sse = 0\n",
        "        epoch_mse = 0\n",
        "        no_observations = 0  # Observations used for training so far\n",
        "\n",
        "        for step, batch in enumerate(train_iter):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            target = batch[2].to(device)\n",
        "    \n",
        "\n",
        "            output = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask, \n",
        "                           labels=target)\n",
        "        \n",
        "            loss, predictions = output[:2]\n",
        "           # attentions = output[2].item()\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                        \n",
        "            sse, mse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy()) \n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_sse += sse \n",
        "            epoch_mse += mse * target.shape[0]\n",
        "\n",
        "        valid_loss, valid_mse, __, __ = eval2(dev_iter, model)\n",
        "\n",
        "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_mse / no_observations\n",
        "\n",
        "        train_losses[epoch-1] = epoch_loss\n",
        "        valid_losses[epoch-1] = valid_loss\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {np.sqrt(epoch_mse):.2f} | \\\n",
        "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {np.sqrt(valid_mse):.2f} |')\n",
        "    return train_losses, valid_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYoIP1F3EW6W"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "# We evaluate performance on our dev set\n",
        "def eval2(dev_iter, model):\n",
        "    \"\"\"\n",
        "    Evaluating model performance on the dev set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_sse = 0\n",
        "    epoch_mse = 0\n",
        "    pred_all = []\n",
        "    trg_all = []\n",
        "    no_observations = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dev_iter:\n",
        "            \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            target = batch[2].to(device)\n",
        "\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            output = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask,\n",
        "                          labels=target) \n",
        "            loss, predictions = output[:2] \n",
        " \n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # We get the mse\n",
        "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
        "            sse, mse, rmse = model_performance(pred, trg)\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_sse += sse\n",
        "            epoch_mse += mse*target.shape[0]\n",
        "            pred_all.extend(pred)\n",
        "            trg_all.extend(trg)\n",
        "    \n",
        "\n",
        "    return epoch_loss/no_observations, epoch_mse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMwsi9MZEkaT"
      },
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "    \"\"\"\n",
        "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
        "    \"\"\"\n",
        "\n",
        "    sq_error = (output - target)**2\n",
        "\n",
        "    sse = np.sum(sq_error)\n",
        "    mse = np.mean(sq_error)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    if print_output:\n",
        "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
        "\n",
        "    return sse, mse, rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gwAy-noir9I",
        "outputId": "793302e5-4018-4068-f19c-2cb9c0500477"
      },
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "train_losses, valid_losses = train2(train_iter, eval_iter, model, 5)\n",
        "plot(train_losses, valid_losses, len(train_losses))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model.\n",
            "| Epoch: 01 | Train Loss: 0.44 | Train MSE: 0.45 | Train RMSE: 0.67 |         Val. Loss: 0.34 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n",
            "| Epoch: 02 | Train Loss: 0.33 | Train MSE: 0.39 | Train RMSE: 0.62 |         Val. Loss: 0.33 | Val. MSE: 0.40 |  Val. RMSE: 0.63 |\n",
            "| Epoch: 03 | Train Loss: 0.31 | Train MSE: 0.39 | Train RMSE: 0.62 |         Val. Loss: 0.33 | Val. MSE: 0.40 |  Val. RMSE: 0.63 |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7f1ef22a8cb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-81ae03ae9b81>\u001b[0m in \u001b[0;36mtrain2\u001b[0;34m(train_iter, dev_iter, model, number_epoch)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mepoch_mse\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mno_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_mse\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mno_observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-8d2c572658c5>\u001b[0m in \u001b[0;36meval2\u001b[0;34m(dev_iter, model)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Accumulate the validation loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mtotal_eval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# We get the mse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2a--D1-pk7G",
        "outputId": "d58d83e4-0fa1-4c9a-c1a1-3f0c72b9dcc5"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', # the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 1,  \n",
        "    output_attentions = True, # don't return attention weights or hidden states\n",
        "    output_hidden_states = False, \n",
        ")\n",
        "model.cuda()\n",
        "#store double values\n",
        "model = model.double()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CIOMXLgPkd4M",
        "outputId": "c66ee921-9b90-4602-842f-bbf0acfb635a"
      },
      "source": [
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "train_losses, valid_losses = train2(train_iter, eval_iter, model, 10)\n",
        "plot(train_losses, valid_losses, len(train_losses))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model.\n",
            "tensor(0.2925, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4572, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4004, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3323, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4470, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4172, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5018, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3259, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2684, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5062, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3713, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3900, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3100, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3598, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4166, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4581, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3952, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4489, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3755, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3432, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3686, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3399, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2790, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3556, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3103, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3285, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3342, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4668, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3884, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3679, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4227, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2825, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3052, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3755, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3469, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4332, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4362, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4898, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3234, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3747, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3527, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3400, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3799, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3085, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3823, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3246, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4120, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3544, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3349, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3847, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3297, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4169, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2924, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3036, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3988, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3876, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3033, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3756, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2595, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3906, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3894, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3626, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3911, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3325, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3823, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2565, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2990, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3237, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4581, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3206, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3978, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2771, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3482, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3634, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4375, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3633, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3955, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3739, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3449, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3710, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3577, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4360, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3534, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3717, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3351, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3445, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5165, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3901, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3846, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4985, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3333, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3516, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3508, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2804, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3620, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3834, device='cuda:0', dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-1c9110290479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-5b7ad2f1df63>\u001b[0m in \u001b[0;36mtrain2\u001b[0;34m(train_iter, dev_iter, model, number_epoch)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0msse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# Update the learning rate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "EfFNl-fNNNxD",
        "outputId": "757e5618-0fda-47a3-f9b7-db8e00b7a472"
      },
      "source": [
        "\n",
        "\n",
        "epochs = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "rmse = []\n",
        "\n",
        "for e in training_stats:\n",
        "  epochs.append(e['epoch'])\n",
        "  training_loss.append(e['Training Loss'])\n",
        "  validation_loss.append(e['Valid. Loss'])\n",
        "  rmse.append(e['Valid. RMSE.'])\n",
        "\n",
        "plt.plot(epochs, training_loss, color = 'blue', label = 'training loss')\n",
        "plt.plot(epochs, validation_loss, color = 'green', label = 'validation loss')\n",
        "plt.title(\"Training and validation loss per epoch\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, rmse)\n",
        "plt.title(\"RMSE per epoch\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-fd099ebeea5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_stats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mtraining_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_stats' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klgk-IngaRLa"
      },
      "source": [
        "\n",
        "#### Approach 2: No pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK9C7EeEaRLc"
      },
      "source": [
        "train_and_dev = train_df['edit']\n",
        "\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n",
        "                                                                        test_size=(1-train_proportion),\n",
        "                                                                        random_state=42)\n",
        "\n",
        "# We train a Tf-idf model\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "train_counts = count_vect.fit_transform(training_data)\n",
        "transformer = TfidfTransformer().fit(train_counts)\n",
        "train_counts = transformer.transform(train_counts)\n",
        "regression_model = LinearRegression().fit(train_counts, training_y)\n",
        "\n",
        "# Train predictions\n",
        "predicted_train = regression_model.predict(train_counts)\n",
        "\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
        "\n",
        "test_counts = count_vect.transform(dev_data)\n",
        "\n",
        "test_counts = transformer.transform(test_counts)\n",
        "\n",
        "# Dev predictions\n",
        "predicted = regression_model.predict(test_counts)\n",
        "\n",
        "# We run the evaluation:\n",
        "print(\"\\nTrain performance:\")\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\n",
        "\n",
        "print(\"\\nDev performance:\")\n",
        "sse, mse = model_performance(predicted, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lRZxL-gD40S"
      },
      "source": [
        "\n",
        "class BiLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2label = nn.Linear(hidden_dim * 2, 1)\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\n",
        "               torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embedded = self.embedding(sentence)\n",
        "        embedded = embedded.permute(1, 0, 2) #Needed for LSTMs\n",
        "\n",
        "        #lstm_out : (seq_len,batch_size,num_directions (2) * hidden_size (50))\n",
        "        #hidden : (num_layers * num_directions, batch_size,hidden_size)\n",
        "        lstm_out, self.hidden = self.lstm(\n",
        "            embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\n",
        "\n",
        "        #out : (1)\n",
        "        out = self.hidden2label(lstm_out[-1]\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSZbSxUbaRLc"
      },
      "source": [
        "#### Baseline for task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwwE7oj0aRLd"
      },
      "source": [
        "# Baseline for the task\n",
        "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
        "print(\"\\nBaseline performance:\")\n",
        "sse, mse = model_performance(pred_baseline, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vs5_tGhaRLd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}