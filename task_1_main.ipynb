{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "task_1_main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3PxOsuS7Bi0g"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ab52aaa5d5641ff90b7c700c070789e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bfcde54aeec74ed385839befc0e62cb4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_01ee20a7efd74550af9b34c55de5651e",
              "IPY_MODEL_4ab879e6764f4f81939958fab04a6e59"
            ]
          }
        },
        "bfcde54aeec74ed385839befc0e62cb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01ee20a7efd74550af9b34c55de5651e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2e2af6ebfaf4787b23d50241d0db8a0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59bc5a94d0b1475d8978e1cb23ed3bed"
          }
        },
        "4ab879e6764f4f81939958fab04a6e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e14b56ecd3474a1ebe115a41e1960563",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 618B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eccc688275a14306ad3c566549ab6c13"
          }
        },
        "d2e2af6ebfaf4787b23d50241d0db8a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59bc5a94d0b1475d8978e1cb23ed3bed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e14b56ecd3474a1ebe115a41e1960563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eccc688275a14306ad3c566549ab6c13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c20469d45c0040a79bdb2f888e99119f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_579b51e3061841ff8ea62c56d528d973",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f44dc94b499648d4810cb22add3f68b7",
              "IPY_MODEL_45cfcafd740041c08a48567df7cc1892"
            ]
          }
        },
        "579b51e3061841ff8ea62c56d528d973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f44dc94b499648d4810cb22add3f68b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2da63f193b1e4f12a08cbfadd65fbb2b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1491f630197c48bda7663a125964d34b"
          }
        },
        "45cfcafd740041c08a48567df7cc1892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25bfb5a51a3e4317b74f3e9375e75b9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:11&lt;00:00, 40.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83ed1a9d7c48470daf3021653e7dea39"
          }
        },
        "2da63f193b1e4f12a08cbfadd65fbb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1491f630197c48bda7663a125964d34b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25bfb5a51a3e4317b74f3e9375e75b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83ed1a9d7c48470daf3021653e7dea39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNppdFiGaRLE"
      },
      "source": [
        "### Coursework coding instructions (please also see full coursework spec)\n",
        "\n",
        "Please choose if you want to do either Task 1 or Task 2. You should write your report about one task only.\n",
        "\n",
        "For the task you choose you will need to do two approaches:\n",
        "  - Approach 1, which can use use pre-trained embeddings / models\n",
        "  - Approach 2, which should not use any pre-trained embeddings or models\n",
        "We should be able to run both approaches from the same colab file\n",
        "\n",
        "#### Running your code:\n",
        "  - Your models should run automatically when running your colab file without further intervention\n",
        "  - For each task you should automatically output the performance of both models\n",
        "  - Your code should automatically download any libraries required\n",
        "\n",
        "#### Structure of your code:\n",
        "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
        "  - Otherwise there are no restrictions on what you can do in your code\n",
        "\n",
        "#### Documentation:\n",
        "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
        "\n",
        "#### Reproducibility:\n",
        "  - Your .README file should explain how to replicate the different experiments mentioned in your report\n",
        "\n",
        "Good luck! We are really looking forward to seeing your reports and your model code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8IanU_MaRLH"
      },
      "source": [
        "#Todo\n",
        "#Remove punctuation\n",
        "#Use embedding that represents headslines\n",
        "#Tokenizer with special token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WfDREnZaRLI",
        "outputId": "a5ff1ea5-f7dc-4c68-ab93-4d83920726b9"
      },
      "source": [
        "# You will need to download any word embeddings required for your code, e.g.:\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n",
        "\n",
        "#! pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-18 08:09:38--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-02-18 08:09:38--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-02-18 08:09:38--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: â€˜glove.6B.zip.1â€™\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  2.01MB/s    in 6m 52s  \n",
            "\n",
            "2021-02-18 08:16:30 (2.00 MB/s) - â€˜glove.6B.zip.1â€™ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of glove.6B.zip or\n",
            "        glove.6B.zip.zip, and cannot find glove.6B.zip.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYZiUqXFghTY",
        "outputId": "f8bf9ed6-0b8c-4909-e287-3ef3fcd8fb60"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6XoHzG_bHDo",
        "outputId": "60a78c85-420a-4d2c-a853-d2c8d0eb7c62"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8MB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2MB 15.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 28.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=5828d7019735789f3178db97bd78cce485480979cffad5740a4eea267f9977cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFcC8gvDaRLI"
      },
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import codecs\n",
        "from transformers import RobertaTokenizer, RobertaModel, BertTokenizer, BertModel, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import re\n",
        "import pdb\n",
        "import random\n",
        "import csv\n",
        "import tqdm\n",
        "import multiprocessing\n",
        "import pickle\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84OyAVNSaRLJ",
        "outputId": "68323911-6d8f-435a-fe3c-9bb7118209b3"
      },
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "2gxbblziaRLK",
        "outputId": "a6324fcc-7b5f-4bf9-8a25-99e93447fb06"
      },
      "source": [
        "# Load data\n",
        "%mkdir ./data\n",
        "%cd ./data\n",
        "import os\n",
        "\n",
        "if not os.path.isfile('train.csv'): \n",
        "  !wget -O train.csv https://www.dropbox.com/s/utcewlslgwm278m/train.csv?dl=0\n",
        "if not os.path.isfile('dev.csv'): \n",
        "  !wget -O dev.csv https://www.dropbox.com/s/0bpqmpb009ay717/dev.csv?dl=0\n",
        "    \n",
        "%cd ..\n",
        "\n",
        "train_df = pd.read_csv('./data/train.csv')\n",
        "test_df = pd.read_csv('./data/dev.csv')\n",
        "train_df"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory â€˜./dataâ€™: File exists\n",
            "/content/data\n",
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14530</td>\n",
              "      <td>France is â€˜ hunting down its citizens who join...</td>\n",
              "      <td>twins</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13034</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian tr...</td>\n",
              "      <td>bowling</td>\n",
              "      <td>33110</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8731</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor ...</td>\n",
              "      <td>party</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76</td>\n",
              "      <td>In an apparent first , Iran and Israel &lt;engage...</td>\n",
              "      <td>slap</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6164</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled &lt;Vi...</td>\n",
              "      <td>school</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9647</th>\n",
              "      <td>10899</td>\n",
              "      <td>State officials blast ' unprecedented ' DHS &lt;m...</td>\n",
              "      <td>idea</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9648</th>\n",
              "      <td>1781</td>\n",
              "      <td>Protesters Rally for &lt;Refugees/&gt; Detained at J...</td>\n",
              "      <td>stewardesses</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9649</th>\n",
              "      <td>5628</td>\n",
              "      <td>Cruise line Carnival Corp. joins the fight aga...</td>\n",
              "      <td>raisin</td>\n",
              "      <td>21000</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9650</th>\n",
              "      <td>14483</td>\n",
              "      <td>Columbia police hunt woman seen with &lt;gun/&gt; ne...</td>\n",
              "      <td>cake</td>\n",
              "      <td>32200</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9651</th>\n",
              "      <td>5255</td>\n",
              "      <td>Here 's What 's In The House-Approved Health &lt;...</td>\n",
              "      <td>food</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9652 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... meanGrade\n",
              "0     14530  ...       0.2\n",
              "1     13034  ...       1.6\n",
              "2      8731  ...       1.0\n",
              "3        76  ...       0.4\n",
              "4      6164  ...       0.0\n",
              "...     ...  ...       ...\n",
              "9647  10899  ...       0.0\n",
              "9648   1781  ...       0.4\n",
              "9649   5628  ...       0.6\n",
              "9650  14483  ...       1.4\n",
              "9651   5255  ...       0.4\n",
              "\n",
              "[9652 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "aMrfmRD0rPJ_",
        "outputId": "19fa4d71-e386-44ff-854d-41d88d6d6f90"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14530</td>\n",
              "      <td>France is â€˜ hunting down its citizens who join...</td>\n",
              "      <td>twins</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13034</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian tr...</td>\n",
              "      <td>bowling</td>\n",
              "      <td>33110</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8731</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor ...</td>\n",
              "      <td>party</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76</td>\n",
              "      <td>In an apparent first , Iran and Israel &lt;engage...</td>\n",
              "      <td>slap</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6164</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled &lt;Vi...</td>\n",
              "      <td>school</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9647</th>\n",
              "      <td>10899</td>\n",
              "      <td>State officials blast ' unprecedented ' DHS &lt;m...</td>\n",
              "      <td>idea</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9648</th>\n",
              "      <td>1781</td>\n",
              "      <td>Protesters Rally for &lt;Refugees/&gt; Detained at J...</td>\n",
              "      <td>stewardesses</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9649</th>\n",
              "      <td>5628</td>\n",
              "      <td>Cruise line Carnival Corp. joins the fight aga...</td>\n",
              "      <td>raisin</td>\n",
              "      <td>21000</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9650</th>\n",
              "      <td>14483</td>\n",
              "      <td>Columbia police hunt woman seen with &lt;gun/&gt; ne...</td>\n",
              "      <td>cake</td>\n",
              "      <td>32200</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9651</th>\n",
              "      <td>5255</td>\n",
              "      <td>Here 's What 's In The House-Approved Health &lt;...</td>\n",
              "      <td>food</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9652 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... meanGrade\n",
              "0     14530  ...       0.2\n",
              "1     13034  ...       1.6\n",
              "2      8731  ...       1.0\n",
              "3        76  ...       0.4\n",
              "4      6164  ...       0.0\n",
              "...     ...  ...       ...\n",
              "9647  10899  ...       0.0\n",
              "9648   1781  ...       0.4\n",
              "9649   5628  ...       0.6\n",
              "9650  14483  ...       1.4\n",
              "9651   5255  ...       0.4\n",
              "\n",
              "[9652 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQbm--SyaRLL"
      },
      "source": [
        "# Number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# Proportion of training data for train compared to dev\n",
        "train_proportion = 0.8"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PxOsuS7Bi0g"
      },
      "source": [
        "### Training for BILSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxhwWCz6aRLL"
      },
      "source": [
        "# We define our training loop\n",
        "def train(train_iter, dev_iter, model, number_epoch, bert=False):\n",
        "    \"\"\"\n",
        "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "    \"\"\"\n",
        "\n",
        "    train_losses = np.zeros(number_epoch)\n",
        "    valid_losses = np.zeros(number_epoch)\n",
        "    print(\"Training model.\")\n",
        "\n",
        "    for epoch in range(1, number_epoch+1):\n",
        "\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_sse = 0\n",
        "        no_observations = 0  # Observations used for training so far\n",
        "\n",
        "        for batch in train_iter:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            feature, target = batch\n",
        "            feature_1= feature[0].to(device)\n",
        "            feature_2 = feature[1].to(device)\n",
        "            target = target.to(device)\n",
        "            # for RNN:\n",
        "            model.batch_size = target.shape[0]\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            model.hidden_1 = model.init_hidden()\n",
        "            model.hidden_2 = model.init_hidden()\n",
        "\n",
        "            feature = (feature_1, feature_2)\n",
        "            predictions = model(feature).squeeze(1)\n",
        "\n",
        "            #print(predictions.shape)\n",
        "            #print(target.shape)\n",
        "\n",
        "            loss = loss_fn(predictions, target)\n",
        "                        \n",
        "            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy()) \n",
        "            \n",
        "            loss.backward(retain_graph=True)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_sse += sse\n",
        "\n",
        "        valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
        "\n",
        "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
        "        train_losses[epoch-1] = epoch_loss\n",
        "        valid_losses[epoch-1] = valid_loss\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
        "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')\n",
        "    return train_losses, valid_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAPacdgOaRLM"
      },
      "source": [
        "# We evaluate performance on our dev set\n",
        "def eval(data_iter, model):\n",
        "    \"\"\"\n",
        "    Evaluating model performance on the dev set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_sse = 0\n",
        "    pred_all = []\n",
        "    trg_all = []\n",
        "    no_observations = 0\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_iter:\n",
        "            feature, target = batch\n",
        "            feature_1= feature[0].to(device)\n",
        "            feature_2 = feature[1].to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            feature = (feature_1, feature_2)\n",
        "\n",
        "            # for RNN:\n",
        "            model.batch_size = target.shape[0]\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            model.hidden_1 = model.init_hidden()\n",
        "            model.hidden_2 = model.init_hidden()\n",
        "\n",
        "            predictions = model(feature).squeeze(1)\n",
        "            #predictions.requires_grad = True\n",
        "            loss = loss_fn(predictions, target)\n",
        "\n",
        "            # We get the mse\n",
        "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
        "            sse, __ = model_performance(pred, trg)\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_sse += sse\n",
        "            pred_all.extend(pred)\n",
        "            trg_all.extend(trg)\n",
        "\n",
        "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcchQKtEaRLN"
      },
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "    \"\"\"\n",
        "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
        "    \"\"\"\n",
        "\n",
        "    sq_error = (output - target)**2\n",
        "\n",
        "    sse = np.sum(sq_error)\n",
        "    mse = np.mean(sq_error)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    if print_output:\n",
        "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
        "\n",
        "    return sse, mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "uO4Kv0URaRLN",
        "outputId": "c0470287-1bbe-4a9d-99c1-21cec8abdff8"
      },
      "source": [
        "'''\n",
        "def create_vocab(data):\n",
        "    \"\"\"\n",
        "    Creating a corpus of all the tokens used\n",
        "    \"\"\"\n",
        "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
        "\n",
        "    for sentence in data:\n",
        "\n",
        "        tokenized_sentence = []\n",
        "\n",
        "        for token in sentence.split(' '): # simplest split is\n",
        "\n",
        "            tokenized_sentence.append(token)\n",
        "\n",
        "        tokenized_corpus.append(tokenized_sentence)\n",
        "\n",
        "    # Create single list of all vocabulary\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "    for sentence in tokenized_corpus:\n",
        "\n",
        "        for token in sentence:\n",
        "\n",
        "            if token not in vocabulary:\n",
        "\n",
        "                if True:\n",
        "                    vocabulary.append(token)\n",
        "\n",
        "    return vocabulary, tokenized_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-d3ae31c862b2>\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    return vocabulary, tokenized_corpus\u001b[0m\n\u001b[0m                                       \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSQ-36SdaRLO"
      },
      "source": [
        "# To create our vocab\n",
        "\n",
        "def custom_tokenizer(nlp):\n",
        "    \n",
        "    replacement_re = re.compile(r'^<*/>') #do not split replacement format\n",
        "    prefix_re = re.compile(r'''^[\\[\\(\"]''')\n",
        "    suffix_re = re.compile(r''',[\\]\\)\"']$''')\n",
        "    infix_re = re.compile(r'''[-\\,.~]''')\n",
        "    \n",
        "    \n",
        "    return Tokenizer(nlp.vocab,\n",
        "                     token_match = replacement_re.match,\n",
        "                     prefix_search=prefix_re.search,\n",
        "                     suffix_search=suffix_re.search,\n",
        "                     infix_finditer = infix_re.finditer  \n",
        "                    )\n",
        "\n",
        "\n",
        "\n",
        "def preprocessor(data,edits):\n",
        "    \"\"\"\n",
        "    Creating a corpus of all the tokens used\n",
        "    \"\"\"\n",
        "    punctuation = \"\\\":\\.,\"\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    nlp.tokenizer = custom_tokenizer(nlp)\n",
        "    \n",
        "    tokenized_corpus_1= [] # Let us put the tokenized corpus in a list\n",
        "    tokenized_corpus_2= []\n",
        "    \n",
        "    \n",
        "    for i, sentence in enumerate(data):\n",
        "\n",
        "        sentence = sentence.lower()\n",
        "        tokenized_sentence_1 = []\n",
        "        tokenized_sentence_2 = []\n",
        "\n",
        "        for token in nlp(sentence): # simplest split is\n",
        "\n",
        "            if token.text in punctuation:\n",
        "                continue\n",
        "            else:\n",
        "                \n",
        "                if token.text[0] == '<':\n",
        "                    tokenized_sentence_1.append(\"???\")\n",
        "                    tokenized_sentence_2.append(\"???\")\n",
        "                    \n",
        "                    tokenized_sentence_2.append(edits[i])\n",
        "\n",
        "                    \n",
        "                    tokenized_sentence_1.append(token.text[1:-2])\n",
        "                else:\n",
        "                    tokenized_sentence_2.append(token.text)\n",
        "                \n",
        "                    tokenized_sentence_1.append(token.text)\n",
        "\n",
        "\n",
        "        tokenized_corpus_1.append(tokenized_sentence_1)\n",
        "        tokenized_corpus_2.append(tokenized_sentence_2)\n",
        "        #print(tokenized_corpus_1[:5])\n",
        "        #print(tokenized_corpus_2[:5])\n",
        "\n",
        "    # Create single list of all vocabulary\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "    for sentence in tokenized_corpus_1:\n",
        "\n",
        "        for token in sentence:\n",
        "\n",
        "            if token not in vocabulary:\n",
        "\n",
        "                if True:\n",
        "                    vocabulary.append(token)\n",
        "    \n",
        "    for token in edits:\n",
        "        \n",
        "        if token not in vocabulary:\n",
        "            \n",
        "            vocabulary.append(token)\n",
        "\n",
        "    return vocabulary, tokenized_corpus_1, tokenized_corpus_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_faSla0aknz"
      },
      "source": [
        "'''\n",
        "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def preprocessor_bert(data,edits):\n",
        "    \"\"\"\n",
        "    Creating a corpus of all the tokens used\n",
        "    \"\"\"\n",
        "    next = False\n",
        "    punctuation = \"\\\":\\.,\"\n",
        "    #nlp = spacy.load(\"en_core_web_sm\")\n",
        "    \n",
        "    #nlp.tokenizer = custom_tokenizer(nlp)\n",
        "    \n",
        "    tokenized_corpus_1= [] # Let us put the tokenized corpus in a list\n",
        "    tokenized_corpus_2= []\n",
        "    tokenized_mask_corpus = []\n",
        "    \n",
        "    \n",
        "    for i, sentence in enumerate(data):\n",
        "\n",
        "        sentence = sentence.lower()\n",
        "        tokenized_sentence_1 = []\n",
        "        tokenized_sentence_2 = []\n",
        "        tokenized_mask_sentence = []\n",
        "\n",
        "        for token in tokenizer_bert.tokenize(sentence): # simplest split is\n",
        "\n",
        "            if token in punctuation:\n",
        "                continue\n",
        "            else:\n",
        "                \n",
        "                if token == '<':\n",
        "                    print(token)\n",
        "                    next = True\n",
        "\n",
        "                    \n",
        "                    #tokenized_sentence_2.append(edits[i])\n",
        "\n",
        "                    \n",
        "                    #tokenized_sentence_1.append(token[1:-2])\n",
        "                elif token == '>' or token == '/':\n",
        "                    continue\n",
        "                else:\n",
        "                    tokenized_sentence_1.append(token)\n",
        "                    \n",
        "                    if next:\n",
        "                        tokenized_sentence_2.append(edits[i])\n",
        "                        tokenized_mask_sentence.append(1)\n",
        "                        next = False\n",
        "                    else:\n",
        "                        tokenized_sentence_2.append(token)\n",
        "                        tokenized_mask_sentence.append(0)\n",
        "                \n",
        "        tokenized_corpus_1.append(tokenized_sentence_1)\n",
        "        tokenized_corpus_2.append(tokenized_sentence_2)\n",
        "        tokenized_mask_corpus.append(tokenized_mask_sentence)\n",
        "        print(tokenized_corpus_1[:5])\n",
        "        print(tokenized_corpus_2[:5])\n",
        "        print(tokenized_mask_corpus[:5])\n",
        "        if i==3:\n",
        "          raise\n",
        "    # Create single list of all vocabulary\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "    for sentence in tokenized_corpus_1:\n",
        "\n",
        "        for token in sentence:\n",
        "\n",
        "            if token not in vocabulary:\n",
        "\n",
        "                if True:\n",
        "                    vocabulary.append(token)\n",
        "    \n",
        "    for token in edits:\n",
        "        \n",
        "        if token not in vocabulary:\n",
        "            \n",
        "            vocabulary.append(token)\n",
        "\n",
        "    return vocabulary, tokenized_corpus_1, tokenized_corpus_2\n",
        "preprocessor_bert(training_data,train_df['edit'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOOe3Ca7aRLP"
      },
      "source": [
        "'''def collate_fn_padd(batch):\n",
        "    #We add padding to our minibatches and create tensors for our model\n",
        "\n",
        "\n",
        "    batch_labels = [l for f, l in batch]\n",
        "    batch_features = [f for f, l in batch]\n",
        "\n",
        "    batch_features_len = [len(f) for f, l in batch]\n",
        "\n",
        "    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
        "\n",
        "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
        "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
        "\n",
        "    batch_labels = torch.FloatTensor(batch_labels)\n",
        "\n",
        "    return seq_tensor, batch_labels\n",
        "'''\n",
        "def collate_fn_padd(batch):\n",
        "    \n",
        "    #We add padding to our minibatches and create tensors for our model\n",
        "    \n",
        "\n",
        "    batch_labels = [l for f, g, l in batch]\n",
        "    batch_features = [(f,g) for f, g, l in batch]\n",
        "    \n",
        "\n",
        "    batch_features_len = [len(f) for f, g, l in batch]\n",
        "\n",
        "\n",
        "    seq_tensor_1 = torch.zeros((len(batch), 50)).long()\n",
        "    seq_tensor_2 = torch.zeros((len(batch), 50)).long()\n",
        "\n",
        "    \n",
        "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
        "        seq_tensor_1[idx, :seqlen] = torch.LongTensor(seq[0])\n",
        "        seq_tensor_2[idx, :seqlen] = torch.LongTensor(seq[1])\n",
        "    batch_labels = torch.FloatTensor(batch_labels)\n",
        "    \n",
        "\n",
        "    return (seq_tensor_1, seq_tensor_2), batch_labels\n",
        "\n",
        "'''\n",
        "def collate_fn_pad(batch):\n",
        "\n",
        "    original, edit, labels = zip(*batch)\n",
        "    padded_original = torch.nn.utils.rnn.pad_sequence(original, batch_first=True,padding_value=0)\n",
        "    padded_edit = torch.nn.utils.rnn.pad_sequence(edit, batch_first=True,padding_value=0)\n",
        "    labels = torch.Tensor(labels)\n",
        "    return (padded_org, padded_edit, labels)\n",
        "'''\n",
        "\n",
        "\n",
        "class Task1Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, train_data, labels):\n",
        "        self.x_train = train_data\n",
        "        self.y_train = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_train)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.x_train[item], self.y_train[item]\n",
        "    \n",
        "class Task1Dataset_double(Dataset):\n",
        "\n",
        "    def __init__(self, train_data_1,train_data_2, labels):\n",
        "        self.x_train_1 = train_data_1\n",
        "        self.x_train_2 = train_data_2\n",
        "        self.y_train = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_train)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.x_train_1[item],self.x_train_2[item], self.y_train[item]    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F1kXohWaRLR"
      },
      "source": [
        "class BiLSTM_double(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
        "        super(BiLSTM_double, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm_1 = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "        self.lstm_2 = nn.LSTM(embedding_dim,hidden_dim, bidirectional = True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.fc = nn.Linear(2*50*100, hidden_dim*2)\n",
        "        self.fc2 = nn.Linear(hidden_dim*2, hidden_dim//2)\n",
        "        self.fc3 = nn.Linear(hidden_dim//2, hidden_dim//4)\n",
        "\n",
        "        self.hidden_1 = self.init_hidden()\n",
        "        self.hidden_2 = self.init_hidden()\n",
        "        self.hidden2label = nn.Linear(hidden_dim//4, 1)\n",
        "\n",
        "\n",
        "        self.d1 = nn.Dropout(0.3)\n",
        "        self.d2 = nn.Dropout(0.3)\n",
        "        self.d3 = nn.Dropout(0.3)\n",
        "        self.d4 = nn.Dropout(0.3)\n",
        "        self.d5 = nn.Dropout(0.3)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "        \n",
        "        return torch.zeros(2, self.batch_size, self.hidden_dim, requires_grad = True).to(self.device), \\\n",
        "               torch.zeros(2, self.batch_size, self.hidden_dim, requires_grad = True).to(self.device)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        self.embedded_1 = self.embedding(sentence[0])\n",
        "        self.embedded_1 = self.embedded_1.permute(1, 0, 2) #Needed for LSTMs\n",
        "\n",
        "        self.embedded_2 = self.embedding(sentence[1])\n",
        "        self.embedded_2 = self.embedded_2.permute(1, 0, 2) #Needed for LSTMs\n",
        "\n",
        "        #lstm_out : (seq_len,batch_size,num_directions (2) * hidden_size (50))\n",
        "        #hidden : (num_layers * num_directions, batch_size,hidden_size)\n",
        "        lstm_out_1, self.hidden_1 = self.lstm_1(\n",
        "            self.embedded_1.view(len(self.embedded_1), self.batch_size, self.embedding_dim), self.hidden_1)\n",
        "        \n",
        "        lstm_out_1 = F.leaky_relu(self.d1(lstm_out_1))\n",
        "\n",
        "        lstm_out_2, self.hidden_2 = self.lstm_2(\n",
        "            self.embedded_2.view(len(self.embedded_2), self.batch_size, self.embedding_dim), self.hidden_2)\n",
        "        \n",
        "        lstm_out_2 = F.leaky_relu(self.d2(lstm_out_2))\n",
        "        \n",
        "        #out : (1)\n",
        "        lstm_out_1 = lstm_out_1.permute(1,0,2)\n",
        "        lstm_out_2 = lstm_out_2.permute(1,0,2)\n",
        "\n",
        "        out1 = self.fc(torch.cat((lstm_out_1.reshape(self.batch_size, -1),lstm_out_2.reshape(self.batch_size, -1)), dim = 1))\n",
        "        out1 = F.leaky_relu(self.d3(out1))\n",
        "\n",
        "        out2 = self.fc2(out1)\n",
        "        out2 = F.leaky_relu(self.d4(out2))\n",
        "\n",
        "        out3 = self.fc3(out2)\n",
        "        out3 = F.leaky_relu(self.d5(out3))\n",
        "\n",
        "        out = self.hidden2label(out3)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JSWm-Q5nIxX"
      },
      "source": [
        "##Â Approach 1 code, using functions defined above:\n",
        "\n",
        "# We set our training data and test data\n",
        "training_data = train_df['original']\n",
        "test_data = test_df['original']\n",
        "\n",
        "# Creating word vectors\n",
        "#training_vocab, training_tokenized_corpus = create_vocab(training_data)\n",
        "#test_vocab, test_tokenized_corpus = create_vocab(test_data)\n",
        "training_vocab, training_tokenized_corpus_1,training_tokenized_corpus_2=  preprocessor(training_data,train_df['edit'])\n",
        "test_vocab, test_tokenized_corpus_1,test_tokenized_corpus_2=  preprocessor(test_data,test_df['edit'])\n",
        "\n",
        "#print(\"Vocabulary individual creation - done\")\n",
        "\n",
        "# Creating joint vocab from test and train:\n",
        "#joint_vocab, joint_tokenized_corpus = create_vocab(pd.concat([training_data, test_data]))\n",
        "joint_vocab, joint_tokenized_corpus_1,joint_tokenized_corpus_2 = preprocessor(pd.concat([training_data, test_data]),pd.concat([train_df['edit'],test_df['edit']],ignore_index = True))\n",
        "\n",
        "print(\"Vocabulary joined creation - done\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Vocab created.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeXy7v7dnQGq"
      },
      "source": [
        "# We create representations for our tokens\n",
        "wvecs = [] # word vectors\n",
        "word2idx = [] # word2index\n",
        "idx2word = []\n",
        "\n",
        "#Add special character -> embedding vector of ones \n",
        "wvecs.append(np.ones(100))\n",
        "\n",
        "# This is a large file, it will take a while to load in the memory!\n",
        "with codecs.open('glove.6B.100d.txt', 'r','utf-8') as f:\n",
        "  index = 1 #zero padding\n",
        "  for line in f.readlines():\n",
        "    # Ignore the first line - first line typically contains vocab, dimensionality\n",
        "    if len(line.strip().split()) > 3:\n",
        "      word = line.strip().split()[0]\n",
        "      if word in joint_vocab:\n",
        "          (word, vec) = (word,\n",
        "                     list(map(float,line.strip().split()[1:])))\n",
        "          wvecs.append(vec)\n",
        "          word2idx.append((word, index))\n",
        "          idx2word.append((index, word))\n",
        "          index += 1\n",
        "\n",
        "wvecs = np.array(wvecs)\n",
        "word2idx = dict(word2idx)\n",
        "idx2word = dict(idx2word)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ze3glIrVMmj"
      },
      "source": [
        "word2idx['<unk>'] = 1\n",
        "idx2word[1] = '<unk>'\n",
        "mean = np.mean(wvecs, axis=0) # initialize unknown token as mean\n",
        "#wvecs = np.vstack((wvecs, mean))\n",
        "wvecs[0] = mean\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgcGpchbQOO-"
      },
      "source": [
        "\n",
        "\n",
        "vectorized_seqs_1 = [[word2idx[tok] if tok in word2idx else word2idx['<unk>'] for tok in seq] for seq in training_tokenized_corpus_1]\n",
        "vectorized_seqs_2 = [[word2idx[tok] if tok in word2idx else word2idx['<unk>'] for tok in seq] for seq in training_tokenized_corpus_2]\n",
        "\n",
        "\n",
        "# To avoid any sentences being empty (if no words match to our word embeddings)\n",
        "vectorized_seqs_1 = [x if len(x) > 0 else [0] for x in vectorized_seqs_1]\n",
        "vectorized_seqs_2 = [x if len(x) > 0 else [0] for x in vectorized_seqs_2]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XzJHcQ_aRLT",
        "scrolled": true
      },
      "source": [
        "\n",
        "INPUT_DIM = len(word2idx)\n",
        "EMBEDDING_DIM = wvecs.shape[1]\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "model = BiLSTM_double(EMBEDDING_DIM, 50, INPUT_DIM, BATCH_SIZE, device)\n",
        "\n",
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(params)\n",
        "#print(\"Total number of parameters is: {â€‹â€‹}â€‹â€‹\".format(params))\n",
        "\n",
        "print(model)\n",
        "\n",
        "print(\"Model initialised.\")\n",
        "\n",
        "model.to(device)\n",
        "# We provide the model with our embeddings\n",
        "#x = np.concatenate((wvecs,wvecs),axis=1)\n",
        "model.embedding.weight.data.copy_(torch.from_numpy(wvecs))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8ovZX23ECX4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot(train_losses,valid_losses,num_epochs):\n",
        "  epochs = list(range(num_epochs))\n",
        "  plt.plot(epochs,train_losses, label='train')\n",
        "  plt.plot(epochs,valid_losses, label='valid')\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un9wo5TPyN9L"
      },
      "source": [
        "\n",
        "feature_1 = vectorized_seqs_1\n",
        "feature_2 = vectorized_seqs_2\n",
        "\n",
        "\n",
        "# 'feature' is a list of lists, each containing embedding IDs for word tokens\n",
        "#train_and_dev = Task1Dataset(feature, train_df['meanGrade'])\n",
        "train_and_dev = Task1Dataset_double(feature_1,feature_2, train_df['meanGrade'])\n",
        "\n",
        "train_examples = round(len(train_and_dev)*train_proportion)\n",
        "dev_examples = len(train_and_dev) - train_examples\n",
        "train_dataset, dev_dataset = random_split(train_and_dev,\n",
        "                                           (train_examples,\n",
        "                                            dev_examples))\n",
        "####Shuffle might need to be true. Check later\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
        "\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
        "\n",
        "print(\"Dataloaders created.\")\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "#optimizer = torch.optim.Adam(model.parameters())\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "train_losses, valid_losses = train(train_loader, dev_loader, model, epochs)\n",
        "plot(train_losses, valid_losses, len(train_losses))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJHjgo5XEELW"
      },
      "source": [
        "# BERT VERSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huUfT43sLAmc"
      },
      "source": [
        "## Bert Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YhnKBjYLIoG"
      },
      "source": [
        " def add_columns_to_data(train_df, test_df):   \n",
        "    #instead of having two inputs out of preprocessing, edit the dataset, and add in columns which we can use as inputs\n",
        "    #we can also add an 'old' field which contains the original word \n",
        "    train_df['old'] = train_df.apply(lambda x:x['original'][x['original'].find('<')+1:x['original'].find('>')-1],axis=1)\n",
        "    test_df['old'] = test_df.apply(lambda x:x['original'][x['original'].find('<')+1:x['original'].find('>')-1],axis=1)\n",
        "\n",
        "    #first we add a field to the data which contains the edited headline\n",
        "    train_df['edited'] = train_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],x['edit'] ) ,axis=1)\n",
        "    test_df['edited'] = test_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1], x['edit'] ) ,axis=1)\n",
        "\n",
        "    train_df['original'] = train_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1], x['old']) ,axis=1)\n",
        "    test_df['original'] = test_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1], x['old']),axis=1)\n",
        "\n",
        "    return train_df, test_df"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K1hafJCyjy-"
      },
      "source": [
        "train_df, test_df = add_columns_to_data(train_df, test_df)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WFKfFOHqyPi"
      },
      "source": [
        "def data_to_list(data, training = True):  \n",
        "  og_headline_list = data['original'].tolist()\n",
        "  edited_headline_list = data['edited'].tolist()\n",
        "  edited_word_list = data['edit'].tolist()\n",
        "  labels_list = None\n",
        "  if training:\n",
        "    labels_list = data['meanGrade'].tolist()\n",
        "\n",
        "  return og_headline_list, edited_headline_list, edited_word_list, labels_list"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwe8nrN0zW0x"
      },
      "source": [
        "train_og_headlines, train_edited_headlines, train_edited_words, labels = data_to_list(train_df)\n",
        "test_og_headlines, test_edited_headlines, test_edited_words, _ = data_to_list(test_df, training=False)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC7yLY8L0LHr"
      },
      "source": [
        "def preprocessing(data_list):\n",
        "  preprocessed_data = []\n",
        "  for sentence in data_list:\n",
        "    sentence = re.sub(r'[^\\w\\s\\?\\!]', '', sentence)\n",
        "    sentence = sentence.lower()\n",
        "    preprocessed_data.append(sentence)\n",
        "  return preprocessed_data\n",
        "\n",
        "train_og_headlines_p = preprocessing(train_og_headlines)\n",
        "train_edited_headlines_p = preprocessing(train_edited_headlines)\n",
        "train_edited_words_p = preprocessing(train_edited_words)\n",
        "\n",
        "test_og_headlines_p = preprocessing(test_og_headlines)\n",
        "test_edited_headlines_p = preprocessing(test_edited_headlines)\n",
        "test_edited_words_p = preprocessing(test_edited_words)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUoiGvGvz7te"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "# the version that concatenates original sentences and new sentences\n",
        "train_encoded_inputs = tokenizer(train_og_headlines_p, train_edited_headlines_p, padding='max_length', max_length=90, truncation=True, return_tensors=\"pt\")\n",
        "test_encoded_inputs = tokenizer(test_og_headlines_p, test_edited_headlines_p, padding='max_length', max_length=90, truncation=True, return_tensors=\"pt\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "ebgbzfrm4idz",
        "outputId": "25f196da-ad30-4c4e-ba2e-e1f0a8e37560"
      },
      "source": [
        "train_input_ids = train_encoded_inputs['input_ids']\n",
        "train_attention_mask = train_encoded_inputs['attention_mask']\n",
        "train_token_type_ids = train_encoded_inputs['token_type_ids']\n",
        "train_labels = torch.tensor(labels)\n",
        "\n",
        "train_token_type_ids[0]\n",
        "tokenizer.decode(train_input_ids.tolist()[1])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] pentagon claims 2000 increase in russian trolls after syria strikes what does that mean? [SEP] pentagon claims 2000 increase in russian trolls after bowling strikes what does that mean? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9brja9zLFR4"
      },
      "source": [
        "## Bert Training/Eval\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeKy-eWjF9BB"
      },
      "source": [
        "#Hyperparameters\n",
        "train_proportion = 0.8\n",
        "batch_size = 64\n",
        "lr = 5e-5\n",
        "eps = 1e-8\n",
        "epochs = 4"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l6PAI0t4Fbq"
      },
      "source": [
        "class BERT_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x1, x2, x3, y1):\n",
        "        self.len = x1.shape[0]\n",
        "\n",
        "        self.x1_data = x1.to(device)\n",
        "        self.x2_data = x2.to(device)\n",
        "        self.x3_data = x3.to(device)\n",
        "        self.y1_data = y1.to(device)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x1_data[index], self.x2_data[index], self.x3_data[index], self.y1_data[index]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSlXJEGPQlhn"
      },
      "source": [
        "\n",
        "\n",
        "train_and_dev = BERT_Dataset(train_input_ids, train_attention_mask, train_token_type_ids, train_labels)\n",
        "train_examples = round(len(train_and_dev)*train_proportion)\n",
        "dev_examples = len(train_and_dev) - train_examples\n",
        "train_dataset, dev_dataset = random_split(train_and_dev,(train_examples,dev_examples))\n",
        "\n",
        "\n",
        "train_iter = DataLoader(\n",
        "            train_dataset, \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "eval_iter = DataLoader(\n",
        "            dev_dataset, \n",
        "            sampler = SequentialSampler(dev_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "9ab52aaa5d5641ff90b7c700c070789e",
            "bfcde54aeec74ed385839befc0e62cb4",
            "01ee20a7efd74550af9b34c55de5651e",
            "4ab879e6764f4f81939958fab04a6e59",
            "d2e2af6ebfaf4787b23d50241d0db8a0",
            "59bc5a94d0b1475d8978e1cb23ed3bed",
            "e14b56ecd3474a1ebe115a41e1960563",
            "eccc688275a14306ad3c566549ab6c13",
            "c20469d45c0040a79bdb2f888e99119f",
            "579b51e3061841ff8ea62c56d528d973",
            "f44dc94b499648d4810cb22add3f68b7",
            "45cfcafd740041c08a48567df7cc1892",
            "2da63f193b1e4f12a08cbfadd65fbb2b",
            "1491f630197c48bda7663a125964d34b",
            "25bfb5a51a3e4317b74f3e9375e75b9e",
            "83ed1a9d7c48470daf3021653e7dea39"
          ]
        },
        "id": "NvvC0JgPFRyU",
        "outputId": "1b74ef32-95f5-42c5-d5d3-7527dd48fa27"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', # the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 1,  \n",
        "    output_attentions = False, # don't return attention weights or hidden states\n",
        "    output_hidden_states = False, \n",
        ")\n",
        "model.cuda()\n",
        "#store double values\n",
        "model = model.double()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ab52aaa5d5641ff90b7c700c070789e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c20469d45c0040a79bdb2f888e99119f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6kGoEa-RQn7"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = lr, eps = eps)\n",
        "\n",
        "total_steps = len(train_iter) * epochs\n",
        "# The scheduler can actually learn the best learning rate throughout tranining\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TrotOmSEG-n"
      },
      "source": [
        "# We define our training loop\n",
        "def train2(train_iter, dev_iter, model, number_epoch):\n",
        "    \"\"\"\n",
        "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "    \"\"\"\n",
        "\n",
        "    train_losses = np.zeros(number_epoch)\n",
        "    valid_losses = np.zeros(number_epoch)\n",
        "    print(\"Training model.\")\n",
        "\n",
        "\n",
        "    for epoch in range(1, number_epoch+1):\n",
        "\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_sse = 0\n",
        "        epoch_mse = 0\n",
        "        no_observations = 0  # Observations used for training so far\n",
        "\n",
        "        for step, batch in enumerate(train_iter):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            target = batch[2].to(device)\n",
        "    \n",
        "\n",
        "            output = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask, \n",
        "                           labels=target)\n",
        "        \n",
        "            loss, predictions = output[:2]\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                        \n",
        "            sse, mse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy()) \n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_sse += sse \n",
        "            epoch_mse += mse * target.shape[0]\n",
        "\n",
        "        valid_loss, valid_mse, __, __ = eval2(dev_iter, model)\n",
        "\n",
        "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_mse / no_observations\n",
        "\n",
        "        train_losses[epoch-1] = epoch_loss\n",
        "        valid_losses[epoch-1] = valid_loss\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {np.sqrt(epoch_mse):.2f} | \\\n",
        "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {np.sqrt(valid_mse):.2f} |')\n",
        "    return train_losses, valid_losses"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYoIP1F3EW6W"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "# We evaluate performance on our dev set\n",
        "def eval2(dev_iter, model):\n",
        "    \"\"\"\n",
        "    Evaluating model performance on the dev set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_sse = 0\n",
        "    epoch_mse = 0\n",
        "    pred_all = []\n",
        "    trg_all = []\n",
        "    no_observations = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dev_iter:\n",
        "            \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            target = batch[2].to(device)\n",
        "\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            output = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask,\n",
        "                          labels=target) \n",
        "            loss, predictions = output[:2] \n",
        " \n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # We get the mse\n",
        "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
        "            sse, mse, rmse = model_performance(pred, trg)\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_sse += sse\n",
        "            epoch_mse += mse*target.shape[0]\n",
        "            pred_all.extend(pred)\n",
        "            trg_all.extend(trg)\n",
        "    \n",
        "\n",
        "    return epoch_loss/no_observations, epoch_mse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMwsi9MZEkaT"
      },
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "    \"\"\"\n",
        "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
        "    \"\"\"\n",
        "\n",
        "    sq_error = (output - target)**2\n",
        "\n",
        "    sse = np.sum(sq_error)\n",
        "    mse = np.mean(sq_error)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    if print_output:\n",
        "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
        "\n",
        "    return sse, mse, rmse"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "2gwAy-noir9I",
        "outputId": "6543a9d0-8011-4a9a-9189-f87c821a9e95"
      },
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "train_losses, valid_losses = train2(train_iter, eval_iter, model, 5)\n",
        "plot(train_losses, valid_losses, len(train_losses))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model.\n",
            "| Epoch: 01 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |         Val. Loss: 0.36 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n",
            "| Epoch: 02 | Train Loss: 0.34 | Train MSE: 0.36 | Train RMSE: 0.60 |         Val. Loss: 0.34 | Val. MSE: 0.37 |  Val. RMSE: 0.60 |\n",
            "| Epoch: 03 | Train Loss: 0.33 | Train MSE: 0.36 | Train RMSE: 0.60 |         Val. Loss: 0.34 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n",
            "| Epoch: 04 | Train Loss: 0.32 | Train MSE: 0.37 | Train RMSE: 0.61 |         Val. Loss: 0.34 | Val. MSE: 0.38 |  Val. RMSE: 0.62 |\n",
            "| Epoch: 05 | Train Loss: 0.32 | Train MSE: 0.37 | Train RMSE: 0.61 |         Val. Loss: 0.34 | Val. MSE: 0.38 |  Val. RMSE: 0.62 |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIOMXLgPkd4M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "9cf11a79-6414-4309-fa51-2b9a391f2c41"
      },
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "train_losses, valid_losses = train2(train_iter, eval_iter, model, 10)\n",
        "plot(train_losses, valid_losses, len(train_losses))\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([5760])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-6b164ec8df57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-4dc510ae3d6b>\u001b[0m in \u001b[0;36mtrain2\u001b[0;34m(train_iter, dev_iter, model, number_epoch)\u001b[0m\n\u001b[1;32m     29\u001b[0m                            \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                            labels=target)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1516\u001b[0m                 \u001b[0;31m#  We are doing regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (5760) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "EfFNl-fNNNxD",
        "outputId": "757e5618-0fda-47a3-f9b7-db8e00b7a472"
      },
      "source": [
        "\n",
        "\n",
        "epochs = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "rmse = []\n",
        "\n",
        "for e in training_stats:\n",
        "  epochs.append(e['epoch'])\n",
        "  training_loss.append(e['Training Loss'])\n",
        "  validation_loss.append(e['Valid. Loss'])\n",
        "  rmse.append(e['Valid. RMSE.'])\n",
        "\n",
        "plt.plot(epochs, training_loss, color = 'blue', label = 'training loss')\n",
        "plt.plot(epochs, validation_loss, color = 'green', label = 'validation loss')\n",
        "plt.title(\"Training and validation loss per epoch\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, rmse)\n",
        "plt.title(\"RMSE per epoch\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-fd099ebeea5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_stats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mtraining_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_stats' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klgk-IngaRLa"
      },
      "source": [
        "\n",
        "#### Approach 2: No pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK9C7EeEaRLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935eba3b-ba63-4a6f-b373-842f8e627f1d"
      },
      "source": [
        "train_and_dev = train_df['edit']\n",
        "\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n",
        "                                                                        test_size=(1-train_proportion),\n",
        "                                                                        random_state=42)\n",
        "\n",
        "# We train a Tf-idf model\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "train_counts = count_vect.fit_transform(training_data)\n",
        "transformer = TfidfTransformer().fit(train_counts)\n",
        "transformer\n",
        "train_counts = transformer.transform(train_counts)\n",
        "regression_model = LinearRegression().fit(train_counts, training_y)\n",
        "print(train_counts)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 587)\t1.0\n",
            "  (1, 1510)\t1.0\n",
            "  (2, 1580)\t1.0\n",
            "  (3, 2401)\t1.0\n",
            "  (4, 3388)\t1.0\n",
            "  (5, 643)\t1.0\n",
            "  (6, 2290)\t1.0\n",
            "  (7, 634)\t1.0\n",
            "  (8, 287)\t1.0\n",
            "  (9, 271)\t1.0\n",
            "  (10, 1545)\t1.0\n",
            "  (11, 880)\t1.0\n",
            "  (12, 915)\t1.0\n",
            "  (13, 2761)\t1.0\n",
            "  (14, 3701)\t1.0\n",
            "  (15, 1779)\t1.0\n",
            "  (16, 3635)\t1.0\n",
            "  (17, 2869)\t1.0\n",
            "  (18, 2137)\t1.0\n",
            "  (19, 903)\t1.0\n",
            "  (20, 3966)\t1.0\n",
            "  (21, 452)\t1.0\n",
            "  (22, 3443)\t1.0\n",
            "  (23, 906)\t1.0\n",
            "  (24, 3416)\t1.0\n",
            "  :\t:\n",
            "  (7696, 220)\t1.0\n",
            "  (7697, 472)\t1.0\n",
            "  (7698, 2924)\t1.0\n",
            "  (7699, 2356)\t1.0\n",
            "  (7700, 1100)\t1.0\n",
            "  (7701, 1042)\t1.0\n",
            "  (7702, 1678)\t1.0\n",
            "  (7703, 1021)\t1.0\n",
            "  (7704, 3645)\t1.0\n",
            "  (7705, 2065)\t1.0\n",
            "  (7706, 895)\t1.0\n",
            "  (7707, 1098)\t1.0\n",
            "  (7708, 1029)\t1.0\n",
            "  (7709, 208)\t1.0\n",
            "  (7710, 2551)\t1.0\n",
            "  (7711, 3346)\t1.0\n",
            "  (7712, 3755)\t1.0\n",
            "  (7713, 2777)\t1.0\n",
            "  (7714, 2532)\t1.0\n",
            "  (7715, 1663)\t1.0\n",
            "  (7716, 920)\t1.0\n",
            "  (7717, 3191)\t1.0\n",
            "  (7718, 3890)\t1.0\n",
            "  (7719, 1290)\t1.0\n",
            "  (7720, 1499)\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AInKATQT6pXE"
      },
      "source": [
        "\n",
        "# Train predictions\n",
        "predicted_train = regression_model.predict(train_counts)\n",
        "\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
        "\n",
        "test_counts = count_vect.transform(dev_data)\n",
        "\n",
        "test_counts = transformer.transform(test_counts)\n",
        "\n",
        "# Dev predictions\n",
        "predicted = regression_model.predict(test_counts)\n",
        "\n",
        "# We run the evaluation:\n",
        "print(\"\\nTrain performance:\")\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\n",
        "\n",
        "print(\"\\nDev performance:\")\n",
        "sse, mse = model_performance(predicted, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lRZxL-gD40S"
      },
      "source": [
        "\n",
        "class BiLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2label = nn.Linear(hidden_dim * 2, 1)\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\n",
        "               torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embedded = self.embedding(sentence)\n",
        "        embedded = embedded.permute(1, 0, 2) #Needed for LSTMs\n",
        "\n",
        "        #lstm_out : (seq_len,batch_size,num_directions (2) * hidden_size (50))\n",
        "        #hidden : (num_layers * num_directions, batch_size,hidden_size)\n",
        "        lstm_out, self.hidden = self.lstm(\n",
        "            embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\n",
        "\n",
        "        #out : (1)\n",
        "        out = self.hidden2label(lstm_out[-1]\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSZbSxUbaRLc"
      },
      "source": [
        "#### Baseline for task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwwE7oj0aRLd"
      },
      "source": [
        "#Â Baseline for the task\n",
        "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
        "print(\"\\nBaseline performance:\")\n",
        "sse, mse = model_performance(pred_baseline, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vs5_tGhaRLd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}