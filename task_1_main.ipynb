{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNppdFiGaRLE"
   },
   "source": [
    "### Coursework coding instructions (please also see full coursework spec)\n",
    "\n",
    "Please choose if you want to do either Task 1 or Task 2. You should write your report about one task only.\n",
    "\n",
    "For the task you choose you will need to do two approaches:\n",
    "  - Approach 1, which can use use pre-trained embeddings / models\n",
    "  - Approach 2, which should not use any pre-trained embeddings or models\n",
    "We should be able to run both approaches from the same colab file\n",
    "\n",
    "#### Running your code:\n",
    "  - Your models should run automatically when running your colab file without further intervention\n",
    "  - For each task you should automatically output the performance of both models\n",
    "  - Your code should automatically download any libraries required\n",
    "\n",
    "#### Structure of your code:\n",
    "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
    "  - Otherwise there are no restrictions on what you can do in your code\n",
    "\n",
    "#### Documentation:\n",
    "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
    "\n",
    "#### Reproducibility:\n",
    "  - Your .README file should explain how to replicate the different experiments mentioned in your report\n",
    "\n",
    "Good luck! We are really looking forward to seeing your reports and your model code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8IanU_MaRLH"
   },
   "outputs": [],
   "source": [
    "#Todo\n",
    "#Remove punctuation\n",
    "#Use embedding that represents headslines\n",
    "#Tokenizer with special token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WfDREnZaRLI",
    "outputId": "85c66385-aa12-428c-93d2-f88eee690c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-11 14:42:12--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-02-11 14:42:12--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-02-11 14:42:13--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  2.17MB/s    in 6m 51s  \n",
      "\n",
      "2021-02-11 14:49:04 (2.00 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "# You will need to download any word embeddings required for your code, e.g.:\n",
    "\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip\n",
    "\n",
    "# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n",
    "\n",
    "#! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TYZiUqXFghTY",
    "outputId": "332f60f2-7c43-4847-8920-b066e9a7b5ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kFcC8gvDaRLI"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import codecs\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84OyAVNSaRLJ",
    "outputId": "ef4fce60-0dfe-44aa-82f3-2a2997a6ea95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting random seed and device\n",
    "SEED = 1\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "2gxbblziaRLK",
    "outputId": "f1421511-2aee-4482-d5c0-58f1b1032db9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>edit</th>\n",
       "      <th>grades</th>\n",
       "      <th>meanGrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14530</td>\n",
       "      <td>France is ‘ hunting down its citizens who join...</td>\n",
       "      <td>twins</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13034</td>\n",
       "      <td>Pentagon claims 2,000 % increase in Russian tr...</td>\n",
       "      <td>bowling</td>\n",
       "      <td>33110</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8731</td>\n",
       "      <td>Iceland PM Calls Snap Vote as Pedophile Furor ...</td>\n",
       "      <td>party</td>\n",
       "      <td>22100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>In an apparent first , Iran and Israel &lt;engage...</td>\n",
       "      <td>slap</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6164</td>\n",
       "      <td>Trump was told weeks ago that Flynn misled &lt;Vi...</td>\n",
       "      <td>school</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9647</th>\n",
       "      <td>10899</td>\n",
       "      <td>State officials blast ' unprecedented ' DHS &lt;m...</td>\n",
       "      <td>idea</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9648</th>\n",
       "      <td>1781</td>\n",
       "      <td>Protesters Rally for &lt;Refugees/&gt; Detained at J...</td>\n",
       "      <td>stewardesses</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9649</th>\n",
       "      <td>5628</td>\n",
       "      <td>Cruise line Carnival Corp. joins the fight aga...</td>\n",
       "      <td>raisin</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650</th>\n",
       "      <td>14483</td>\n",
       "      <td>Columbia police hunt woman seen with &lt;gun/&gt; ne...</td>\n",
       "      <td>cake</td>\n",
       "      <td>32200</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651</th>\n",
       "      <td>5255</td>\n",
       "      <td>Here 's What 's In The House-Approved Health &lt;...</td>\n",
       "      <td>food</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9652 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           original          edit  \\\n",
       "0     14530  France is ‘ hunting down its citizens who join...         twins   \n",
       "1     13034  Pentagon claims 2,000 % increase in Russian tr...       bowling   \n",
       "2      8731  Iceland PM Calls Snap Vote as Pedophile Furor ...         party   \n",
       "3        76  In an apparent first , Iran and Israel <engage...          slap   \n",
       "4      6164  Trump was told weeks ago that Flynn misled <Vi...        school   \n",
       "...     ...                                                ...           ...   \n",
       "9647  10899  State officials blast ' unprecedented ' DHS <m...          idea   \n",
       "9648   1781  Protesters Rally for <Refugees/> Detained at J...  stewardesses   \n",
       "9649   5628  Cruise line Carnival Corp. joins the fight aga...        raisin   \n",
       "9650  14483  Columbia police hunt woman seen with <gun/> ne...          cake   \n",
       "9651   5255  Here 's What 's In The House-Approved Health <...          food   \n",
       "\n",
       "      grades  meanGrade  \n",
       "0      10000        0.2  \n",
       "1      33110        1.6  \n",
       "2      22100        1.0  \n",
       "3      20000        0.4  \n",
       "4          0        0.0  \n",
       "...      ...        ...  \n",
       "9647       0        0.0  \n",
       "9648   20000        0.4  \n",
       "9649   21000        0.6  \n",
       "9650   32200        1.4  \n",
       "9651   11000        0.4  \n",
       "\n",
       "[9652 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('task-1/train.csv')\n",
    "test_df = pd.read_csv('task-1/dev.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HQbm--SyaRLL"
   },
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Proportion of training data for train compared to dev\n",
    "train_proportion = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "iDfCSZPUHSQL"
   },
   "outputs": [],
   "source": [
    "x = np.ones((32,25))\n",
    "y = np.ones((32,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BxhwWCz6aRLL"
   },
   "outputs": [],
   "source": [
    "# We define our training loop\n",
    "def train(train_iter, dev_iter, model, number_epoch):\n",
    "    \"\"\"\n",
    "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
    "    \"\"\"\n",
    "\n",
    "    train_losses = np.zeros(number_epoch)\n",
    "    valid_losses = np.zeros(number_epoch)\n",
    "    print(\"Training model.\")\n",
    "\n",
    "    for epoch in range(1, number_epoch+1):\n",
    "\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_sse = 0\n",
    "        no_observations = 0  # Observations used for training so far\n",
    "\n",
    "        for batch in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            feature, target = batch\n",
    "            feature_1= feature[0].to(device)\n",
    "            feature_2 = feature[1].to(device)\n",
    "            target = target.to(device)\n",
    "            # for RNN:\n",
    "            model.batch_size = target.shape[0]\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            model.hidden_1 = model.init_hidden()\n",
    "            model.hidden_2 = model.init_hidden()\n",
    "\n",
    "            feature = (feature_1, feature_2)\n",
    "            predictions = model(feature).squeeze(1)\n",
    "\n",
    "            #print(predictions.shape)\n",
    "            #print(target.shape)\n",
    "\n",
    "            loss = loss_fn(predictions, target)\n",
    "                        \n",
    "            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy()) \n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_sse += sse\n",
    "\n",
    "        valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
    "\n",
    "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
    "        train_losses[epoch-1] = epoch_loss\n",
    "        valid_losses[epoch-1] = valid_loss\n",
    "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
    "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "EAPacdgOaRLM"
   },
   "outputs": [],
   "source": [
    "# We evaluate performance on our dev set\n",
    "def eval(data_iter, model):\n",
    "    \"\"\"\n",
    "    Evaluating model performance on the dev set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_sse = 0\n",
    "    pred_all = []\n",
    "    trg_all = []\n",
    "    no_observations = 0\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_iter:\n",
    "            feature, target = batch\n",
    "            feature_1= feature[0].to(device)\n",
    "            feature_2 = feature[1].to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            feature = (feature_1, feature_2)\n",
    "\n",
    "            # for RNN:\n",
    "            model.batch_size = target.shape[0]\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            model.hidden_1 = model.init_hidden()\n",
    "            model.hidden_2 = model.init_hidden()\n",
    "\n",
    "            predictions = model(feature).squeeze(1)\n",
    "            #predictions.requires_grad = True\n",
    "            loss = loss_fn(predictions, target)\n",
    "\n",
    "            # We get the mse\n",
    "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
    "            sse, __ = model_performance(pred, trg)\n",
    "\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_sse += sse\n",
    "            pred_all.extend(pred)\n",
    "            trg_all.extend(trg)\n",
    "\n",
    "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vcchQKtEaRLN"
   },
   "outputs": [],
   "source": [
    "# How we print the model performance\n",
    "def model_performance(output, target, print_output=False):\n",
    "    \"\"\"\n",
    "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
    "    \"\"\"\n",
    "\n",
    "    sq_error = (output - target)**2\n",
    "\n",
    "    sse = np.sum(sq_error)\n",
    "    mse = np.mean(sq_error)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    if print_output:\n",
    "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
    "\n",
    "    return sse, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uO4Kv0URaRLN"
   },
   "outputs": [],
   "source": [
    "def create_vocab(data):\n",
    "    \"\"\"\n",
    "    Creating a corpus of all the tokens used\n",
    "    \"\"\"\n",
    "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
    "\n",
    "    for sentence in data:\n",
    "\n",
    "        tokenized_sentence = []\n",
    "\n",
    "        for token in sentence.split(' '): # simplest split is\n",
    "\n",
    "            tokenized_sentence.append(token)\n",
    "\n",
    "        tokenized_corpus.append(tokenized_sentence)\n",
    "\n",
    "    # Create single list of all vocabulary\n",
    "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
    "\n",
    "    for sentence in tokenized_corpus:\n",
    "\n",
    "        for token in sentence:\n",
    "\n",
    "            if token not in vocabulary:\n",
    "\n",
    "                if True:\n",
    "                    vocabulary.append(token)\n",
    "\n",
    "    return vocabulary, tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "TSQ-36SdaRLO"
   },
   "outputs": [],
   "source": [
    "# To create our vocab\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    \n",
    "    replacement_re = re.compile(r'^<*/>') #do not split replacement format\n",
    "    prefix_re = re.compile(r'''^[\\[\\(\"]''')\n",
    "    suffix_re = re.compile(r''',[\\]\\)\"']$''')\n",
    "    infix_re = re.compile(r'''[-\\,.~]''')\n",
    "    \n",
    "    \n",
    "    return Tokenizer(nlp.vocab,\n",
    "                     token_match = replacement_re.match,\n",
    "                     prefix_search=prefix_re.search,\n",
    "                     suffix_search=suffix_re.search,\n",
    "                     infix_finditer = infix_re.finditer  \n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "def preprocessor(data,edits):\n",
    "    \"\"\"\n",
    "    Creating a corpus of all the tokens used\n",
    "    \"\"\"\n",
    "    punctuation = \"\\\":\\.,\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nlp.tokenizer = custom_tokenizer(nlp)\n",
    "    \n",
    "    tokenized_corpus_1= [] # Let us put the tokenized corpus in a list\n",
    "    tokenized_corpus_2= []\n",
    "    \n",
    "    \n",
    "    for i, sentence in enumerate(data):\n",
    "\n",
    "        sentence = sentence.lower()\n",
    "        tokenized_sentence_1 = []\n",
    "        tokenized_sentence_2 = []\n",
    "\n",
    "        for token in nlp(sentence): # simplest split is\n",
    "\n",
    "            if token.text in punctuation:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                if token.text[0] == '<':\n",
    "                    tokenized_sentence_1.append(\"???\")\n",
    "                    tokenized_sentence_2.append(\"???\")\n",
    "                    \n",
    "                    tokenized_sentence_2.append(edits[i])\n",
    "\n",
    "                    \n",
    "                    tokenized_sentence_1.append(token.text[1:-2])\n",
    "                else:\n",
    "                    tokenized_sentence_2.append(token.text)\n",
    "                \n",
    "                    tokenized_sentence_1.append(token.text)\n",
    "\n",
    "\n",
    "        tokenized_corpus_1.append(tokenized_sentence_1)\n",
    "        tokenized_corpus_2.append(tokenized_sentence_2)\n",
    "        #print(tokenized_corpus_1[:5])\n",
    "        #print(tokenized_corpus_2[:5])\n",
    "\n",
    "    # Create single list of all vocabulary\n",
    "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
    "\n",
    "    for sentence in tokenized_corpus_1:\n",
    "\n",
    "        for token in sentence:\n",
    "\n",
    "            if token not in vocabulary:\n",
    "\n",
    "                if True:\n",
    "                    vocabulary.append(token)\n",
    "    \n",
    "    for token in edits:\n",
    "        \n",
    "        if token not in vocabulary:\n",
    "            \n",
    "            vocabulary.append(token)\n",
    "\n",
    "    return vocabulary, tokenized_corpus_1, tokenized_corpus_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aOOe3Ca7aRLP"
   },
   "outputs": [],
   "source": [
    "'''def collate_fn_padd(batch):\n",
    "    #We add padding to our minibatches and create tensors for our model\n",
    "\n",
    "\n",
    "    batch_labels = [l for f, l in batch]\n",
    "    batch_features = [f for f, l in batch]\n",
    "\n",
    "    batch_features_len = [len(f) for f, l in batch]\n",
    "\n",
    "    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
    "\n",
    "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
    "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
    "\n",
    "    batch_labels = torch.FloatTensor(batch_labels)\n",
    "\n",
    "    return seq_tensor, batch_labels\n",
    "'''\n",
    "def collate_fn_padd(batch):\n",
    "    \n",
    "    #We add padding to our minibatches and create tensors for our model\n",
    "    \n",
    "\n",
    "    batch_labels = [l for f, g, l in batch]\n",
    "    batch_features = [(f,g) for f, g, l in batch]\n",
    "    \n",
    "\n",
    "    batch_features_len = [len(f) for f, g, l in batch]\n",
    "\n",
    "\n",
    "    seq_tensor_1 = torch.zeros((len(batch), 50)).long()\n",
    "    seq_tensor_2 = torch.zeros((len(batch), 50)).long()\n",
    "\n",
    "    \n",
    "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
    "        seq_tensor_1[idx, :seqlen] = torch.LongTensor(seq[0])\n",
    "        seq_tensor_2[idx, :seqlen] = torch.LongTensor(seq[1])\n",
    "    batch_labels = torch.FloatTensor(batch_labels)\n",
    "    \n",
    "\n",
    "    return (seq_tensor_1, seq_tensor_2), batch_labels\n",
    "\n",
    "'''\n",
    "def collate_fn_pad(batch):\n",
    "\n",
    "    original, edit, labels = zip(*batch)\n",
    "    padded_original = torch.nn.utils.rnn.pad_sequence(original, batch_first=True,padding_value=0)\n",
    "    padded_edit = torch.nn.utils.rnn.pad_sequence(edit, batch_first=True,padding_value=0)\n",
    "    labels = torch.Tensor(labels)\n",
    "    return (padded_org, padded_edit, labels)\n",
    "'''\n",
    "\n",
    "\n",
    "class Task1Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, train_data, labels):\n",
    "        self.x_train = train_data\n",
    "        self.y_train = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.x_train[item], self.y_train[item]\n",
    "    \n",
    "class Task1Dataset_double(Dataset):\n",
    "\n",
    "    def __init__(self, train_data_1,train_data_2, labels):\n",
    "        self.x_train_1 = train_data_1\n",
    "        self.x_train_2 = train_data_2\n",
    "        self.y_train = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.x_train_1[item],self.x_train_2[item], self.y_train[item]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "1alD5n1GaRLR",
    "outputId": "6baf637a-7452-4ab6-af4d-0acd0f2a75b6"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-1b7493fcc32f>, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-1b7493fcc32f>\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    return out\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2label = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
    "        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\n",
    "               torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embedded = self.embedding(sentence)\n",
    "        embedded = embedded.permute(1, 0, 2) #Needed for LSTMs\n",
    "\n",
    "        #lstm_out : (seq_len,batch_size,num_directions (2) * hidden_size (50))\n",
    "        #hidden : (num_layers * num_directions, batch_size,hidden_size)\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\n",
    "\n",
    "        #out : (1)\n",
    "        out = self.hidden2label(lstm_out[-1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "8F1kXohWaRLR"
   },
   "outputs": [],
   "source": [
    "class BiLSTM_double(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
    "        super(BiLSTM_double, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm_1 = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "        self.lstm_2 = nn.LSTM(embedding_dim,hidden_dim, bidirectional = True)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.fc = nn.Linear(2*50*100, hidden_dim*2)\n",
    "        self.fc2 = nn.Linear(hidden_dim*2, hidden_dim//2)\n",
    "\n",
    "        self.hidden_1 = self.init_hidden()\n",
    "        self.hidden_2 = self.init_hidden()\n",
    "        self.hidden2label = nn.Linear(hidden_dim//2, 1)\n",
    "\n",
    "\n",
    "        self.d1 = nn.Dropout(0.5)\n",
    "        self.d2 = nn.Dropout(0.5)\n",
    "        self.d3 = nn.Dropout(0.5)\n",
    "        self.d4 = nn.Dropout(0.5)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
    "        \n",
    "        return torch.zeros(2, self.batch_size, self.hidden_dim, requires_grad = True).to(self.device), \\\n",
    "               torch.zeros(2, self.batch_size, self.hidden_dim, requires_grad = True).to(self.device)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        self.embedded_1 = self.embedding(sentence[0])\n",
    "        self.embedded_1 = self.embedded_1.permute(1, 0, 2) #Needed for LSTMs\n",
    "\n",
    "        self.embedded_2 = self.embedding(sentence[1])\n",
    "        self.embedded_2 = self.embedded_2.permute(1, 0, 2) #Needed for LSTMs\n",
    "\n",
    "        #lstm_out : (seq_len,batch_size,num_directions (2) * hidden_size (50))\n",
    "        #hidden : (num_layers * num_directions, batch_size,hidden_size)\n",
    "        lstm_out_1, self.hidden_1 = self.lstm_1(\n",
    "            self.embedded_1.view(len(self.embedded_1), self.batch_size, self.embedding_dim), self.hidden_1)\n",
    "        \n",
    "        lstm_out_1 = F.leaky_relu(self.d1(lstm_out_1))\n",
    "\n",
    "        lstm_out_2, self.hidden_2 = self.lstm_2(\n",
    "            self.embedded_2.view(len(self.embedded_2), self.batch_size, self.embedding_dim), self.hidden_2)\n",
    "        \n",
    "        lstm_out_2 = F.leaky_relu(self.d2(lstm_out_2))\n",
    "        \n",
    "        #out : (1)\n",
    "        lstm_out_1 = lstm_out_1.permute(1,0,2)\n",
    "        lstm_out_2 = lstm_out_2.permute(1,0,2)\n",
    "\n",
    "        out1 = self.fc(torch.cat((lstm_out_1.reshape(self.batch_size, -1),lstm_out_2.reshape(self.batch_size, -1)), dim = 1))\n",
    "        out1 = F.leaky_relu(self.d3(out1))\n",
    "\n",
    "        out2 = self.fc2(out1)\n",
    "        out2 = F.leaky_relu(self.d4(out2))\n",
    "\n",
    "        out = self.hidden2label(out2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_JSWm-Q5nIxX",
    "outputId": "779db43e-05e2-4d08-cd14-ec7ae5104c29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary individual creation - done\n",
      "Vocabulary joined creation - done\n",
      "Vocab created.\n"
     ]
    }
   ],
   "source": [
    "## Approach 1 code, using functions defined above:\n",
    "\n",
    "# We set our training data and test data\n",
    "training_data = train_df['original']\n",
    "test_data = test_df['original']\n",
    "\n",
    "# Creating word vectors\n",
    "#training_vocab, training_tokenized_corpus = create_vocab(training_data)\n",
    "#test_vocab, test_tokenized_corpus = create_vocab(test_data)\n",
    "#training_vocab, training_tokenized_corpus_1,training_tokenized_corpus_2=  preprocessor(training_data,train_df['edit'])\n",
    "#test_vocab, test_tokenized_corpus_1,test_tokenized_corpus_2=  preprocessor(test_data,test_df['edit'])\n",
    "\n",
    "#print(\"Vocabulary individual creation - done\")\n",
    "\n",
    "# Creating joint vocab from test and train:\n",
    "#joint_vocab, joint_tokenized_corpus = create_vocab(pd.concat([training_data, test_data]))\n",
    "joint_vocab, joint_tokenized_corpus_1,joint_tokenized_corpus_2 = preprocessor(pd.concat([training_data, test_data]),pd.concat([train_df['edit'],test_df['edit']],ignore_index = True))\n",
    "\n",
    "print(\"Vocabulary joined creation - done\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Vocab created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xeXy7v7dnQGq"
   },
   "outputs": [],
   "source": [
    "# We create representations for our tokens\n",
    "wvecs = [] # word vectors\n",
    "word2idx = [] # word2index\n",
    "idx2word = []\n",
    "\n",
    "#Add special character -> embedding vector of ones \n",
    "wvecs.append(np.ones(100))\n",
    "\n",
    "# This is a large file, it will take a while to load in the memory!\n",
    "with codecs.open('glove.6B.100d.txt', 'r','utf-8') as f:\n",
    "  index = 1 #zero padding\n",
    "  for line in f.readlines():\n",
    "    # Ignore the first line - first line typically contains vocab, dimensionality\n",
    "    if len(line.strip().split()) > 3:\n",
    "      word = line.strip().split()[0]\n",
    "      if word in joint_vocab:\n",
    "          (word, vec) = (word,\n",
    "                     list(map(float,line.strip().split()[1:])))\n",
    "          wvecs.append(vec)\n",
    "          word2idx.append((word, index))\n",
    "          idx2word.append((index, word))\n",
    "          index += 1\n",
    "\n",
    "wvecs = np.array(wvecs)\n",
    "word2idx = dict(word2idx)\n",
    "idx2word = dict(idx2word)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0ze3glIrVMmj"
   },
   "outputs": [],
   "source": [
    "word2idx['<unk>'] = 1\n",
    "idx2word[1] = '<unk>'\n",
    "mean = np.mean(wvecs, axis=0) # initialize unknown token as mean\n",
    "#wvecs = np.vstack((wvecs, mean))\n",
    "wvecs[0] = mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BgcGpchbQOO-"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vectorized_seqs_1 = [[word2idx[tok] if tok in word2idx else word2idx['<unk>'] for tok in seq] for seq in training_tokenized_corpus_1]\n",
    "vectorized_seqs_2 = [[word2idx[tok] if tok in word2idx else word2idx['<unk>'] for tok in seq] for seq in training_tokenized_corpus_2]\n",
    "\n",
    "\n",
    "# To avoid any sentences being empty (if no words match to our word embeddings)\n",
    "vectorized_seqs_1 = [x if len(x) > 0 else [0] for x in vectorized_seqs_1]\n",
    "vectorized_seqs_2 = [x if len(x) > 0 else [0] for x in vectorized_seqs_2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4XzJHcQ_aRLT",
    "outputId": "0aa16f80-4388-45eb-fd5b-639df51199ef",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2254651\n",
      "BiLSTM_double(\n",
      "  (embedding): Embedding(11304, 100, padding_idx=0)\n",
      "  (lstm_1): LSTM(100, 50, bidirectional=True)\n",
      "  (lstm_2): LSTM(100, 50, bidirectional=True)\n",
      "  (fc): Linear(in_features=10000, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=25, bias=True)\n",
      "  (hidden2label): Linear(in_features=25, out_features=1, bias=True)\n",
      "  (d1): Dropout(p=0.5, inplace=False)\n",
      "  (d2): Dropout(p=0.5, inplace=False)\n",
      "  (d3): Dropout(p=0.5, inplace=False)\n",
      "  (d4): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Model initialised.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-7.8262e-04,  1.0269e-01,  1.4887e-01,  ..., -6.1605e-02,\n",
       "          2.0113e-01,  8.2360e-02],\n",
       "        [-3.8194e-02, -2.4487e-01,  7.2812e-01,  ..., -1.4590e-01,\n",
       "          8.2780e-01,  2.7062e-01],\n",
       "        [-1.5290e-01, -2.4279e-01,  8.9837e-01,  ..., -5.9100e-01,\n",
       "          1.0039e+00,  2.0664e-01],\n",
       "        ...,\n",
       "        [ 1.9771e-01, -6.8821e-02,  1.9041e-02,  ...,  1.3000e-01,\n",
       "         -2.7314e-01, -4.0290e-02],\n",
       "        [ 1.2610e-01, -2.7248e-01, -3.9575e-01,  ...,  4.6913e-01,\n",
       "          2.1689e-02, -6.4294e-02],\n",
       "        [ 1.9810e-01, -9.9068e-02, -2.7453e-01,  ...,  1.7955e-01,\n",
       "         -3.1754e-01,  1.3571e-01]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "INPUT_DIM = len(word2idx)\n",
    "EMBEDDING_DIM = wvecs.shape[1]\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "model = BiLSTM_double(EMBEDDING_DIM, 50, INPUT_DIM, BATCH_SIZE, device)\n",
    "\n",
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(params)\n",
    "#print(\"Total number of parameters is: {​​}​​\".format(params))\n",
    "\n",
    "print(model)\n",
    "\n",
    "print(\"Model initialised.\")\n",
    "\n",
    "model.to(device)\n",
    "# We provide the model with our embeddings\n",
    "#x = np.concatenate((wvecs,wvecs),axis=1)\n",
    "model.embedding.weight.data.copy_(torch.from_numpy(wvecs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "un9wo5TPyN9L",
    "outputId": "0fd5e0b8-d291-4a6d-eecf-5f6cc5b271d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders created.\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.52 | Train MSE: 0.52 | Train RMSE: 0.72 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 02 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |         Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 03 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.64 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 04 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 05 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n",
      "| Epoch: 06 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 07 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n",
      "| Epoch: 08 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |         Val. Loss: 0.32 | Val. MSE: 0.32 |  Val. RMSE: 0.57 |\n",
      "| Epoch: 09 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.32 | Val. MSE: 0.32 |  Val. RMSE: 0.57 |\n",
      "| Epoch: 10 | Train Loss: 0.23 | Train MSE: 0.23 | Train RMSE: 0.48 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "feature_1 = vectorized_seqs_1\n",
    "feature_2 = vectorized_seqs_2\n",
    "\n",
    "\n",
    "# 'feature' is a list of lists, each containing embedding IDs for word tokens\n",
    "#train_and_dev = Task1Dataset(feature, train_df['meanGrade'])\n",
    "train_and_dev = Task1Dataset_double(feature_1,feature_2, train_df['meanGrade'])\n",
    "\n",
    "train_examples = round(len(train_and_dev)*train_proportion)\n",
    "dev_examples = len(train_and_dev) - train_examples\n",
    "train_dataset, dev_dataset = random_split(train_and_dev,\n",
    "                                           (train_examples,\n",
    "                                            dev_examples))\n",
    "####Shuffle might need to be true. Check later\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "\n",
    "print(\"Dataloaders created.\")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "train_losses, valid_losses = train(train_loader, dev_loader, model, epochs)\n",
    "plot(train_losses, valid_losses, len(train_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "5mwekgglvjbX",
    "outputId": "623543e9-fc6a-4abe-f8d7-3dd6c8d9ea35"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot(train_losses,valid_losses,num_epochs):\n",
    "  epochs = list(range(num_epochs))\n",
    "  plt.plot(epochs,train_losses, label='train')\n",
    "  plt.plot(epochs,valid_losses, label='valid')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Klgk-IngaRLa"
   },
   "source": [
    "\n",
    "#### Approach 2: No pre-trained representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qK9C7EeEaRLc"
   },
   "outputs": [],
   "source": [
    "train_and_dev = train_df['edit']\n",
    "\n",
    "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n",
    "                                                                        test_size=(1-train_proportion),\n",
    "                                                                        random_state=42)\n",
    "\n",
    "# We train a Tf-idf model\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "train_counts = count_vect.fit_transform(training_data)\n",
    "transformer = TfidfTransformer().fit(train_counts)\n",
    "train_counts = transformer.transform(train_counts)\n",
    "regression_model = LinearRegression().fit(train_counts, training_y)\n",
    "\n",
    "# Train predictions\n",
    "predicted_train = regression_model.predict(train_counts)\n",
    "\n",
    "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
    "test_and_test_counts = count_vect.transform(train_and_dev)\n",
    "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
    "\n",
    "test_counts = count_vect.transform(dev_data)\n",
    "\n",
    "test_counts = transformer.transform(test_counts)\n",
    "\n",
    "# Dev predictions\n",
    "predicted = regression_model.predict(test_counts)\n",
    "\n",
    "# We run the evaluation:\n",
    "print(\"\\nTrain performance:\")\n",
    "sse, mse = model_performance(predicted_train, training_y, True)\n",
    "\n",
    "print(\"\\nDev performance:\")\n",
    "sse, mse = model_performance(predicted, dev_y, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSZbSxUbaRLc"
   },
   "source": [
    "#### Baseline for task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "QwwE7oj0aRLd",
    "outputId": "ef8abd4c-a186-4a00-cc8d-8dc44958d2af"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3c7b5eafe872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Baseline for the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nBaseline performance:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_baseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dev_y' is not defined"
     ]
    }
   ],
   "source": [
    "# Baseline for the task\n",
    "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
    "print(\"\\nBaseline performance:\")\n",
    "sse, mse = model_performance(pred_baseline, dev_y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Vs5_tGhaRLd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "task_1_main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
